{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFBKpZCoYD8n"
      },
      "source": [
        "**Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zqdHL7Z_X84C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LWqw4OXWYCay"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-forecasting in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (3.9.1)\n",
            "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.3.3)\n",
            "Requirement already satisfied: optuna<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (3.6.1)\n",
            "Requirement already satisfied: fastapi>=0.80 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (0.111.1)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.5.1)\n",
            "Requirement already satisfied: pytorch-optimizer<3.0.0,>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.12.0)\n",
            "Requirement already satisfied: pandas<=3.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.2.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (0.14.2)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (3.1.4)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (2.2.0)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.27.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (2.8.2)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (4.12.2)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.30.3)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.37.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.0.post0)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.0.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.66.4)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.11.6)\n",
            "Requirement already satisfied: fsspec[http]<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2024.6.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.3.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (2.0.31)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (6.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.5.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.0.106)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (10.3.2.106)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.0)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.3)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.15.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.5.82)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (4.53.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (0.12.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (10.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (3.1.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pytorch-forecasting) (0.5.6)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting) (1.3.5)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi>=0.80->pytorch-forecasting) (3.7)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi>=0.80->pytorch-forecasting) (2.6.1)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (0.12.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.9.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (2024.7.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (4.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.80->pytorch-forecasting) (2.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (59.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pytorch-forecasting) (1.16.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.80->pytorch-forecasting) (2.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.80->pytorch-forecasting) (0.7.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting) (3.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (8.1.7)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (1.0.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (0.6.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (0.22.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (12.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.9.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (23.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.0.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (1.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-forecasting\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJlStn3nKmEe",
        "outputId": "943291d6-9413-4762-d616-233796284312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.0.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tjH01sKKsJu",
        "outputId": "73f6a6f6-f32c-4f8f-ad82-e2ddb9fe9c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlwt in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->torchvision) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install xlwt torchsummary torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWXiuMYzYJIk"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "laZjSYBuYLER"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "import scipy.io\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz3PivL1ZjNq"
      },
      "source": [
        "**Operators.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7KRbWus4ZldZ"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def crossover(x, y):\n",
        "    x = deepcopy(x)\n",
        "    y = deepcopy(y)\n",
        "\n",
        "    '''First parent'''\n",
        "    x_nconv = x.n_conv\n",
        "    x_nfull = x.n_full\n",
        "    xblocks = x.first_level\n",
        "    xbinary = x.second_level\n",
        "\n",
        "    '''Second parent'''\n",
        "    y_nconv = y.n_conv\n",
        "    y_nfull = y.n_full\n",
        "    yblocks = y.first_level\n",
        "    ybinary = y.second_level\n",
        "\n",
        "    '''Convolutional part crossover'''\n",
        "    if x_nconv > y_nconv:\n",
        "        k = math.floor(y_nconv/2)\n",
        "        index = list(range(x_nconv))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(k, y_nconv):\n",
        "            block = yblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            yblocks[i] = xblocks[ix]\n",
        "            xblocks[ix] = block\n",
        "\n",
        "    if y_nconv > x_nconv:\n",
        "        k = math.floor(x_nconv/2)\n",
        "        index = list(range(y_nconv))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(k, x_nconv):\n",
        "            block = xblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            xblocks[i] = yblocks[ix]\n",
        "            yblocks[ix] = block\n",
        "\n",
        "    if x_nconv == y_nconv:\n",
        "        k = math.floor(x_nconv/2)\n",
        "        index = list(range(x_nconv))\n",
        "\n",
        "        x_part = xblocks[k:x_nconv]\n",
        "\n",
        "        '''Exchaning last half of the blocks'''\n",
        "        xblocks[k:x_nconv] = yblocks[k:y_nconv]\n",
        "        yblocks[k:y_nconv] = x_part\n",
        "\n",
        "    '''Fully-connected part'''\n",
        "    if x_nfull > y_nfull:\n",
        "        k = math.floor(y_nfull/2)\n",
        "        index = list(range(x_nconv, x_nconv + x_nfull))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(y_nconv + k, y_nconv + y_nfull):\n",
        "            block = yblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            yblocks[i] = xblocks[ix]\n",
        "            xblocks[ix] = block\n",
        "\n",
        "    if y_nfull > x_nfull:\n",
        "        k = math.floor(x_nfull/2)\n",
        "        index = list(range(y_nconv, y_nconv + y_nfull))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(x_nconv + k, x_nconv + x_nfull):\n",
        "            block = xblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            xblocks[i] = yblocks[ix]\n",
        "            yblocks[ix] = block\n",
        "\n",
        "    if x_nfull == y_nfull:\n",
        "        k = math.floor(x_nfull/2)\n",
        "\n",
        "        x_part = xblocks[x_nconv + k:x_nconv + x_nfull]\n",
        "        '''Exchaning last half of the blocks'''\n",
        "        xblocks[x_nconv + k:x_nconv + x_nfull] = yblocks[y_nconv + k:y_nconv + y_nfull]\n",
        "        yblocks[y_nconv + k:y_nconv + y_nfull] = x_part\n",
        "\n",
        "    '''Second level'''\n",
        "    if len(xbinary) > len(ybinary):\n",
        "        if len(ybinary) > 1 :\n",
        "            k = random.choice(list(range(1, len(ybinary))))\n",
        "            partition = ybinary[k:]\n",
        "            nbits = len(partition)\n",
        "\n",
        "            if random.uniform(0,1) >= 0.5:\n",
        "                ybinary[k:] = xbinary[len(xbinary) - nbits:len(xbinary)]\n",
        "                xbinary[len(xbinary) - nbits:len(xbinary)] = partition\n",
        "            else:\n",
        "                ybinary[k:] = xbinary[:nbits]\n",
        "                xbinary[:nbits] = partition\n",
        "\n",
        "    if len(ybinary) > len(xbinary):\n",
        "        if len(xbinary) > 1 :\n",
        "            k = random.choice(list(range(len(xbinary))))\n",
        "            partition = xbinary[k:]\n",
        "            nbits = len(partition)\n",
        "\n",
        "            if random.uniform(0,1) >= 0.5:\n",
        "                xbinary[k:] = ybinary[len(ybinary) - nbits:len(ybinary)]\n",
        "                ybinary[len(ybinary) - nbits:len(ybinary)] = partition\n",
        "            else:\n",
        "                xbinary[k:] = ybinary[:nbits]\n",
        "                ybinary[:nbits] = partition\n",
        "\n",
        "    if len(xbinary) == len(ybinary):\n",
        "        if len(xbinary) > 1 :\n",
        "            k = random.choice(list(range(len(xbinary))))\n",
        "            partition = xbinary[k:]\n",
        "\n",
        "            xbinary[k:] = ybinary[k:]\n",
        "            ybinary[k:] = partition\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def mutation(x):\n",
        "    if random.uniform(0,1) < 0.5:\n",
        "        '''Adding a new block'''\n",
        "        if random.uniform(0,1) > 0.5:\n",
        "            #Adding a fully-connected block\n",
        "            layer = {'type' : 'fc',\n",
        "                     'neurons' : random.choice(NEURONS)}\n",
        "\n",
        "            #Choosing a random index to insert the new block\n",
        "            index = list(range(x.n_conv, x.n_conv + x.n_full))\n",
        "            ix = random.choice(index)\n",
        "\n",
        "            x.first_level.insert(ix, layer)\n",
        "            x.n_full += 1\n",
        "\n",
        "        else:\n",
        "            #Adding a convolutional block\n",
        "            layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "            #Choosing a random index to insert the new block\n",
        "            index = list(range(x.n_conv))\n",
        "            ix = random.choice(index)\n",
        "\n",
        "            x.first_level.insert(ix, layer)\n",
        "            x.n_conv += 1\n",
        "\n",
        "            if ix > 1:\n",
        "                new_bits = []\n",
        "                for i in range(ix - 1):\n",
        "                    new_bits.append(random.choice([0,1]))\n",
        "                pos = int(0.5*(ix**2) - 1.5*(ix) + 1)\n",
        "                start = pos + len(new_bits)\n",
        "                for bit in new_bits:\n",
        "                    x.second_level.insert(pos, bit)\n",
        "                    pos += 1\n",
        "\n",
        "                rest = x.n_conv - ix - 1\n",
        "                add = ix\n",
        "                for j in range(rest):\n",
        "                    x.second_level.insert(start+add-1, random.choice([0,1]))\n",
        "                    start += add\n",
        "                    ix += 1\n",
        "\n",
        "            if ix == 0 or ix == 1:\n",
        "                if x.n_conv - 1 == 2:\n",
        "                    x.second_level.append(random.choice([0,1]))\n",
        "                else:\n",
        "                    add = 0\n",
        "                    for i in range(2, x.n_conv):\n",
        "                        pos = int(0.5*(ix**2) - 1.5*(ix) + 1) + add\n",
        "                        x.second_level.insert(pos, random.choice([0,1]))\n",
        "                        add += 1\n",
        "\n",
        "    else:\n",
        "        '''Changing hyperparameters in one block'''\n",
        "        if random.uniform(0,1) > 0.5:\n",
        "            '''Re-starting a fully-connected block'''\n",
        "            index = list(range(x.n_conv, x.n_conv + x.n_full))\n",
        "            ix = random.choice(index)\n",
        "            new_layer = {'type' : 'fc',\n",
        "                         'neurons' : random.choice(NEURONS)}\n",
        "            #Switching fully-connected block\n",
        "            x.first_level[ix] = new_layer\n",
        "\n",
        "        else:\n",
        "            '''Re-starting a convolutional block'''\n",
        "            index = list(range(x.n_conv))\n",
        "            ix = random.choice(index)\n",
        "            new_layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "\n",
        "            #Switching convolutional block\n",
        "            x.first_level[ix] = new_layer\n",
        "\n",
        "        '''Modifying connections in second level'''\n",
        "        if len(x.second_level) > 0:\n",
        "            k = random.choice(list(range(len(x.second_level))))\n",
        "            #Flipping one bit in the second level\n",
        "            if x.second_level[k] == 1:\n",
        "                x.second_level[k] = 0\n",
        "            else:\n",
        "                x.second_level[k] = 1\n",
        "\n",
        "\n",
        "def selection(tournament, style):\n",
        "    '''Stochastic tournament selection'''\n",
        "    if style == 'max':\n",
        "        if random.uniform(0,1) <= 0.8:\n",
        "            p = max(tournament, key = lambda x: x[1])\n",
        "        else:\n",
        "            p = random.choice(tournament)\n",
        "    else:\n",
        "        if random.uniform(0,1) <= 0.8:\n",
        "            p = min(tournament, key = lambda x: x[1])\n",
        "        else:\n",
        "            p = random.choice(tournament)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjVfGIiqZVKh"
      },
      "source": [
        "**EncodingClass.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-eXaGfTqZX0B"
      },
      "outputs": [],
      "source": [
        "'''Hyperparameters configuration'''\n",
        "#Convolutional layers\n",
        "'''Hyperparameters configuration'''\n",
        "#Convolutional layers\n",
        "FSIZES = [2,3,4,5,6]\n",
        "#FSIZES = [2,3,4,5,6,7,8]\n",
        "NFILTERS = [2,4,8,16,32]\n",
        "\n",
        "#Pooling layers\n",
        "PSIZES = [2,3,4,5]\n",
        "PTYPE = ['max', 'avg']\n",
        "\n",
        "#Fully connected layers\n",
        "NEURONS = [4,8,16,32,64,128]\n",
        "\n",
        "class Encoding:\n",
        "    def __init__(self, minC, maxC, minF, maxF):\n",
        "        self.n_conv = random.randint(minC, maxC)\n",
        "        self.n_full = random.randint(minF, maxF)\n",
        "\n",
        "\n",
        "        '''First level encoding'''\n",
        "        self.first_level = []\n",
        "\n",
        "        #Feature extraction part\n",
        "        for i in range(self.n_conv):\n",
        "            layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "            self.first_level.append(layer)\n",
        "\n",
        "        #Fully connected part\n",
        "        for i in range(self.n_full):\n",
        "            layer = {'type' : 'fc',\n",
        "                     'neurons' : random.choice(NEURONS)}\n",
        "\n",
        "            self.first_level.append(layer)\n",
        "\n",
        "\n",
        "        '''Second level encoding'''\n",
        "        self.second_level = []\n",
        "        prev = -1\n",
        "        for i in range(self.n_conv):\n",
        "            if prev < 1:\n",
        "                prev += 1\n",
        "            if prev >= 1:\n",
        "                for _ in range(prev-1):\n",
        "                    self.second_level.append(random.choice([0,1]))\n",
        "                prev += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFC3Jg0HL7Hk"
      },
      "source": [
        "**Decondig.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UnLkivWFZc1j"
      },
      "outputs": [],
      "source": [
        "def conv_out_size(W, K):\n",
        "    return W - K + 3\n",
        "\n",
        "def pool_out_size(W, K):\n",
        "    return math.floor((W - K)/2) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ROxmA9hnZekJ"
      },
      "outputs": [],
      "source": [
        "def decoding(encoding):\n",
        "  n_conv = encoding.n_conv\n",
        "  n_full = encoding.n_full\n",
        "  first_level = encoding.first_level\n",
        "  second_level = encoding.second_level\n",
        "\n",
        "  features = []\n",
        "  classifier = []\n",
        "  in_channels = 1\n",
        "  out_size = 92\n",
        "  prev = -1\n",
        "  pos = 0\n",
        "  o_sizes = []\n",
        "  for i in range(n_conv):\n",
        "    layer = first_level[i]\n",
        "    n_filters = layer['nfilters']\n",
        "    f_size = layer['fsize']\n",
        "    pad = 1\n",
        "    if f_size > out_size:\n",
        "        f_size = out_size - 1\n",
        "    if i == 0 or i == 1:\n",
        "      if layer['pool'] == 'off':\n",
        "        operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                    nn.BatchNorm2d(n_filters),\n",
        "                    nn.ReLU(inplace = True)]\n",
        "        in_channels = n_filters\n",
        "        out_size = conv_out_size(out_size, f_size)\n",
        "        o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'avg':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.AvgPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'max':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.MaxPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "    else:\n",
        "      connections = second_level[pos:pos+prev]\n",
        "      for c in range(len(connections)):\n",
        "        if connections[c] == 1:\n",
        "          in_channels += o_sizes[c][1]\n",
        "\n",
        "      if layer['pool'] == 'off':\n",
        "        operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                    nn.BatchNorm2d(n_filters),\n",
        "                    nn.ReLU(inplace = True)]\n",
        "        in_channels = n_filters\n",
        "        out_size = conv_out_size(out_size, f_size)\n",
        "        o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'avg':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.AvgPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'max':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.MaxPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      pos += prev\n",
        "    prev += 1\n",
        "\n",
        "    features.append(operation)\n",
        "  in_size = out_size*out_size*in_channels\n",
        "  for i in range(n_conv,(n_conv + n_full)):\n",
        "    layer = first_level[i]\n",
        "    n_neurons = layer['neurons']\n",
        "    classifier += [nn.Linear(in_size, n_neurons)]\n",
        "    classifier += [nn.ReLU(inplace = True)]\n",
        "    in_size = n_neurons\n",
        "\n",
        "  ##Last layer generates the last neurons for softmax (change this for binary classification)\n",
        "  classifier += [nn.Linear(n_neurons, 6)]\n",
        "\n",
        "  return features, classifier, o_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Hrs1qc3JZhcF"
      },
      "outputs": [],
      "source": [
        "'''Networks class'''\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, encoding, features, classifier, sizes, init_weights = True):\n",
        "    super(CNN, self).__init__()\n",
        "    extraction = []\n",
        "    for layer in features:\n",
        "      extraction += layer\n",
        "    self.extraction = nn.Sequential(*extraction)\n",
        "    self.classifier = nn.Sequential(*classifier)\n",
        "    self.features = features\n",
        "    self.second_level = encoding.second_level\n",
        "    self.sizes = sizes\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''Feature extraction'''\n",
        "    prev = -1\n",
        "    pos = 0\n",
        "    outputs = {}\n",
        "    features = self.features\n",
        "    #print(x.shape)\n",
        "    for i in range(len(features)):\n",
        "      #print('Layer: ', i)\n",
        "      if i == 0 or i == 1:\n",
        "        x = nn.Sequential(*features[i])(x)\n",
        "        outputs[i] = x\n",
        "        #print(x.shape)\n",
        "\n",
        "      else:\n",
        "        connections = self.second_level[pos:pos+prev]\n",
        "        for c in range(len(connections)):\n",
        "          if connections[c] == 1:\n",
        "            skip_size = self.sizes[c][0] #Size comming from previous layer\n",
        "            req_size = x.shape[2] #Current feature map size\n",
        "            #print('X: ',x.shape)\n",
        "            if skip_size > req_size:\n",
        "              psize = skip_size - req_size + 1\n",
        "              pool = nn.MaxPool2d(kernel_size = psize, stride = 1) #Applying pooling to adjust sizes\n",
        "              x2 = pool(outputs[c])\n",
        "            if skip_size == req_size:\n",
        "              x2 = outputs[c]\n",
        "            if req_size == skip_size + 1:\n",
        "              pool = nn.MaxPool2d(kernel_size = 2, stride = 1, padding = (1,1))\n",
        "              x2 = pool(outputs[c])\n",
        "            if req_size == skip_size + 2:\n",
        "              pad = int((req_size - skip_size)/2)\n",
        "              padding = nn.ZeroPad2d(pad)\n",
        "              x2 = padding(outputs[c])\n",
        "            #print('X2: ',x2.shape)\n",
        "            x = torch.cat((x, x2), axis = 1)\n",
        "\n",
        "        x = nn.Sequential(*features[i])(x)\n",
        "        #print('Out size: ', x.shape)\n",
        "        outputs[i] = x\n",
        "        pos += prev\n",
        "\n",
        "      prev += 1\n",
        "\n",
        "    #print('Classification size: ', x.shape)\n",
        "    x = torch.flatten(x,1)\n",
        "    '''Classification'''\n",
        "    '''for l in self.classifier:\n",
        "      x = l(x)'''\n",
        "    x = self.classifier(x)\n",
        "    # return x\n",
        "    #print(x.shape)\n",
        "    return nn.functional.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTbwT-I7ZG6H"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QBRp3dIZJcg",
        "outputId": "6f857d20-6a3e-4158-aebc-69137052b102"
      },
      "outputs": [],
      "source": [
        "# #Mounting Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4e6T3hPGi01"
      },
      "source": [
        "**DataReader.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7byf3HzsZOjR"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.labels = []  # Lista de etiquetas de clase\n",
        "        self.datos = []\n",
        "        file_csv = os.path.join(\n",
        "            root_dir, \"dataset_to_deepga.csv\")\n",
        "        data = np.loadtxt(file_csv, delimiter=',', skiprows=0)\n",
        "        # Removemos la ltima columnas\n",
        "        label = data[:, -1]  # Obtenemos la clase\n",
        "        self.labels = label.astype(int)\n",
        "        self.datos = data[:, :-1]  # Obtenemos los datos\n",
        "        # Seccin para agregar 26 columnas con la finalidad de realizar el reshape\n",
        "        # tam = data.shape[0];\n",
        "        # complemento = np.zeros((tam,26))\n",
        "        # self.datos = np.concatenate([complemento, data], axis=1)\n",
        "        # self.datos = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = self.datos[idx]\n",
        "        # vect2 = np.zeros(26, dtype=float)\n",
        "        # image = np.concatenate([vect2, image], axis=None)\n",
        "        # Redimensionar la imagen a 92\n",
        "        image = np.array(image)\n",
        "        # print(image.shape)\n",
        "        image = image.reshape(92, 92)\n",
        "        [H, W] = image.shape\n",
        "        image = image.reshape((H, W, -1))\n",
        "        # print(image)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        sample = {\"image\": image, \"label\": label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample[\"image\"], sample[\"label\"]\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {\"image\": torch.from_numpy(image), \"label\": label}\n",
        "\n",
        "\n",
        "def loading_data():\n",
        "    root_dir = '../../../../data_img_test'\n",
        "    custom_dataset = CustomDataset(\n",
        "        root_dir=root_dir, transform=transforms.Compose([ToTensor()]))\n",
        "\n",
        "    train_size = int(0.7 * len(custom_dataset))\n",
        "    test_size = len(custom_dataset) - train_size\n",
        "\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        custom_dataset, [train_size, test_size])\n",
        "    # print('Custom datset size : ', len(custom_dataset))\n",
        "    # print('Data size training: ', len(train_dataset))\n",
        "    # print('Data size test: ', len(test_dataset))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=30, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=30, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVmaNMkuLBNN",
        "outputId": "dd09f578-ac25-4dfe-b398-7da8df63ab5a"
      },
      "outputs": [],
      "source": [
        "train_dl, test_dl = loading_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mZ1DCHUPMPry"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 1, 92, 92])\n",
            "tensor([4, 5, 3, 0, 4, 4, 5, 5, 0, 4, 5, 4, 0, 4, 5, 0, 5, 3, 0, 1, 5, 3, 3, 5,\n",
            "        3, 5, 3, 4, 3, 5])\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Dimensiones del tensor test\"\"\"\n",
        "for i_batch,sample_batched in enumerate(test_dl):\n",
        "  print(sample_batched['image'].shape)\n",
        "  print(sample_batched['label'])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "ieYKLeNBMWLx",
        "outputId": "c1805557-884c-42ab-f67d-029cf96ec6bc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_batched['image'][0]\n",
        "imagen = sample_batched['image'][0]\n",
        "imagen = np.squeeze(imagen)\n",
        "# Muestra la imagen en escala de grises\n",
        "plt.imshow(imagen,cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLJ79lVaZ3dB"
      },
      "source": [
        "**DistributedTraining.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "llQFTX8HZ5Ht"
      },
      "outputs": [],
      "source": [
        "def loss_batch(loss_func, xb, yb, yb_h, opt=None):\n",
        "    # Obtain the loss\n",
        "    size_yh = yb_h.size()\n",
        "    size_y = yb.size()\n",
        "    # print(size_yh)\n",
        "    # print(size_y)\n",
        "    loss = loss_func(yb_h, yb)\n",
        "    # Obtain peformance metric\n",
        "    metric_b = metrics_batch(yb, yb_h)\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), metric_b\n",
        "    # return metric_b\n",
        "\n",
        "# Helper function to compute the accuracy per mini_batch\n",
        "\n",
        "\n",
        "def metrics_batch(target, output):\n",
        "    # Obtain output class\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    # Compare output class with target class\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    return corrects\n",
        "\n",
        "# Helper function to compute the loss and metric values for a dataset\n",
        "\n",
        "\n",
        "def loss_epoch(device, model, loss_func, dataset_dl, opt=None):\n",
        "    loss = 0.0\n",
        "    metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "    for i, data in enumerate(dataset_dl, 0):\n",
        "        # print('batch: ', i)\n",
        "        xb, yb = data['image'], data['label']\n",
        "        xb = xb.type(torch.double).to(device, dtype=torch.float32)\n",
        "        yb = yb.to(device, dtype=torch.long)\n",
        "\n",
        "        # Obtain model output\n",
        "        yb_h = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, xb, yb, yb_h, opt)\n",
        "        loss += loss_b\n",
        "        if metric_b is not None:\n",
        "            metric += metric_b\n",
        "\n",
        "    loss /= len_data\n",
        "    metric /= len_data\n",
        "\n",
        "    return loss, metric\n",
        "    # return metric\n",
        "\n",
        "# Define the training function\n",
        "\n",
        "\n",
        "def train_val(device, epochs, model, opt, loss_func, train_dl, test_dl):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # print(epoch)\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(\n",
        "            device, model, loss_func, train_dl, opt)\n",
        "        # train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(\n",
        "                device, model, loss_func, test_dl)\n",
        "            # val_metric = loss_epoch(model, loss_func, test_dl)\n",
        "        accuracy = val_metric\n",
        "\n",
        "        # print(\"Epoch: %d, train loss: %.6f, val loss: %.6f, test accuracy: %.2f\" %(epoch, train_loss, val_loss, accuracy))\n",
        "\n",
        "    return accuracy, model\n",
        "\n",
        "\n",
        "def training(num, device, model, n_epochs, loss_func, train_dl, test_dl, lr, w, max_params):\n",
        "    # Number of parameters\n",
        "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Obtaining training accuracy\n",
        "    accuracy, _ = train_val(device, n_epochs, model, opt,\n",
        "                            loss_func, train_dl, test_dl)\n",
        "\n",
        "    # Fitness function based on accuracy and No. of parameters\n",
        "    # f = abs(accuracy - w*(1 - abs((max_params - params)/max_params)))\n",
        "    f = (1 - w)*accuracy + w*((max_params - params)/max_params)\n",
        "    '''if params < max_params:\n",
        "        f = (1 - w)*accuracy + abs(w*((max_params - params)/max_params))'''\n",
        "    '''else:\n",
        "        #f = (1 - w)*accuracy - abs(w*((max_params - params)/max_params))\n",
        "        f = accuracy - abs((max_params - params)/max_params)'''\n",
        "\n",
        "    # Append results to multiprocessing list\n",
        "    # acc_list.append([num, f, accuracy, params])\n",
        "    return num, f, accuracy, params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieZzagSsYOaj"
      },
      "source": [
        "**Loading GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEdRSBJoYQbx",
        "outputId": "657bceed-5124-4d4a-f88e-17e6670b09cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.cudaStatus.ERROR_NOT_READY)\n",
        "if torch.cuda.is_available():\n",
        "  device1 = torch.device(\"cuda:0\")\n",
        "  # device1 = torch.device(\"cpu\")\n",
        "  print(device1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dXCfouwaYbN"
      },
      "source": [
        "**DeepGA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HCsj6taeabkX"
      },
      "outputs": [],
      "source": [
        "#Maximun and minimum numbers of layers to initialize networks\n",
        "min_conv = 2\n",
        "max_conv = 6\n",
        "min_full = 1\n",
        "max_full = 6\n",
        "\n",
        "'''Genetic Algorithm Parameters'''\n",
        "cr = 0.7 #Crossover rate\n",
        "mr = 0.5 #Mutation rate\n",
        "N = 20 #Population size\n",
        "T = 50 #Number of generations\n",
        "t_size = 6 #tournament size\n",
        "w = 0.3 #penalization weight\n",
        "max_params = 3e6\n",
        "num_epochs = 5 # TODO: retrunt to 50\n",
        "lr = 1e-3\n",
        "# loss_func = nn.NLLLoss(reduction = \"sum\")\n",
        "# loss_func = nn.NLLLoss()\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPU_DA7sbHbe",
        "outputId": "9ef287c9-cf7c-4c56-8d42-b65eb492fc58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialize population\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Given input size: (16x4x4). Calculated output size: (16x0x0). Output size is too small",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m cnn1 \u001b[38;5;241m=\u001b[39m CNN(e1, network1[\u001b[38;5;241m0\u001b[39m], network1[\u001b[38;5;241m1\u001b[39m], network1[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# cnn2 = CNN(e2, network2[0], network2[1], network2[2])\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Evaluate individuals\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m num1, f1, accuracy1, params1 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# training2 = Process(target = training, args = ('2', device2, cnn2, num_epochs, loss_func,\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#                                              train_dl, test_dl, lr, w, max_params, acc_list))\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# if acc_list[0][0] == '1':\u001b[39;00m\n\u001b[1;32m     47\u001b[0m pop\u001b[38;5;241m.\u001b[39mappend([e1, f1, accuracy1, params1])\n",
            "Cell \u001b[0;32mIn[16], line 89\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(num, device, model, n_epochs, loss_func, train_dl, test_dl, lr, w, max_params)\u001b[0m\n\u001b[1;32m     86\u001b[0m opt \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Obtaining training accuracy\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m accuracy, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Fitness function based on accuracy and No. of parameters\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# f = abs(accuracy - w*(1 - abs((max_params - params)/max_params)))\u001b[39;00m\n\u001b[1;32m     94\u001b[0m f \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m w)\u001b[38;5;241m*\u001b[39maccuracy \u001b[38;5;241m+\u001b[39m w\u001b[38;5;241m*\u001b[39m((max_params \u001b[38;5;241m-\u001b[39m params)\u001b[38;5;241m/\u001b[39mmax_params)\n",
            "Cell \u001b[0;32mIn[16], line 64\u001b[0m, in \u001b[0;36mtrain_val\u001b[0;34m(device, epochs, model, opt, loss_func, train_dl, test_dl)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# print(epoch)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 64\u001b[0m     train_loss, train_metric \u001b[38;5;241m=\u001b[39m \u001b[43mloss_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# train_metric = loss_epoch(model, loss_func, train_dl, opt)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
            "Cell \u001b[0;32mIn[16], line 43\u001b[0m, in \u001b[0;36mloss_epoch\u001b[0;34m(device, model, loss_func, dataset_dl, opt)\u001b[0m\n\u001b[1;32m     40\u001b[0m yb \u001b[38;5;241m=\u001b[39m yb\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Obtain model output\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m yb_h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m loss_b, metric_b \u001b[38;5;241m=\u001b[39m loss_batch(loss_func, xb, yb, yb_h, opt)\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_b\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[10], line 51\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m#print('X2: ',x2.shape)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, x2), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#print('Out size: ', x.shape)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m outputs[i] \u001b[38;5;241m=\u001b[39m x\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py:641\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_include_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivisor_override\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (16x4x4). Calculated output size: (16x0x0). Output size is too small"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from multiprocessing import Process, Manager\n",
        "from torchsummary import summary\n",
        "\n",
        "'''Initialize population'''\n",
        "print('Initialize population')\n",
        "\n",
        "# train_dl, test_dl = loading_data()\n",
        "\n",
        "start = timeit.default_timer()\n",
        "pop = []\n",
        "bestAcc = []\n",
        "bestF = []\n",
        "bestParams = []\n",
        "# manager = Manager()\n",
        "while len(pop) < N:\n",
        "    # acc_list = manager.list()\n",
        "\n",
        "    # Creating genomes (genetic encoding)\n",
        "    e1 = Encoding(min_conv, max_conv, min_full, max_full)\n",
        "    # e2 = Encoding(min_conv,max_conv,min_full,max_full)\n",
        "\n",
        "    # Decoding the networks\n",
        "    network1 = decoding(e1)\n",
        "    # network2 = decoding(e2)\n",
        "    # print(network1)\n",
        "\n",
        "    # Creating the CNNs\n",
        "    # print(network1[2])\n",
        "    cnn1 = CNN(e1, network1[0], network1[1], network1[2])\n",
        "    # cnn2 = CNN(e2, network2[0], network2[1], network2[2])\n",
        "    # Evaluate individuals\n",
        "    num1, f1, accuracy1, params1 = training('1', device1, cnn1, num_epochs, loss_func,\n",
        "                                            train_dl, test_dl, lr, w, max_params)\n",
        "\n",
        "    # training2 = Process(target = training, args = ('2', device2, cnn2, num_epochs, loss_func,\n",
        "    #                                              train_dl, test_dl, lr, w, max_params, acc_list))\n",
        "\n",
        "    # training1.start()\n",
        "    # training2.start()\n",
        "    # training1.join()\n",
        "    # training2.join()\n",
        "\n",
        "    # if acc_list[0][0] == '1':\n",
        "    pop.append([e1, f1, accuracy1, params1])\n",
        "    # pop.append([e2, acc_list[1][1], acc_list[1][2], acc_list[1][3]])\n",
        "    # else:\n",
        "    # pop.append([e2, acc_list[0][1], acc_list[0][2], acc_list[0][3]])\n",
        "    # pop.append([e1, acc_list[1][1], acc_list[1][2], acc_list[1][3]])\n",
        "\n",
        "'''Genetic Algorithm'''\n",
        "for t in range(T):\n",
        "    print('Generation: ', t)\n",
        "\n",
        "    # Parents Selection\n",
        "    parents = []\n",
        "    while len(parents) < int(N/2):\n",
        "        # Tournament Selection\n",
        "        tournament = random.sample(pop, t_size)\n",
        "        p1 = selection(tournament, 'max')\n",
        "        tournament = random.sample(pop, t_size)\n",
        "        p2 = selection(tournament, 'max')\n",
        "        while p1 == p2:\n",
        "            tournament = random.sample(pop, t_size)\n",
        "            p2 = selection(tournament, 'max')\n",
        "\n",
        "        parents.append(p1)\n",
        "        parents.append(p2)\n",
        "\n",
        "    # Reproduction\n",
        "    offspring = []\n",
        "    while len(offspring) < int(N/2):\n",
        "        par = random.sample(parents, 2)\n",
        "        # Crossover + Mutation\n",
        "        if cr >= random.uniform(0, 1):  # Crossover\n",
        "            p1 = par[0][0]\n",
        "            p2 = par[1][0]\n",
        "            c1, c2 = crossover(p1, p2)\n",
        "\n",
        "            # Mutation\n",
        "            if mr >= random.uniform(0, 1):\n",
        "                mutation(c1)\n",
        "\n",
        "            if mr >= random.uniform(0, 1):\n",
        "                mutation(c2)\n",
        "\n",
        "            # Evaluate offspring\n",
        "            # acc_list = manager.list()\n",
        "\n",
        "            # Decoding the network\n",
        "            network1 = decoding(c1)\n",
        "            network2 = decoding(c2)\n",
        "\n",
        "            # Creating the CNN\n",
        "            cnn1 = CNN(c1, network1[0], network1[1], network1[2])\n",
        "            cnn2 = CNN(c2, network2[0], network2[1], network2[2])\n",
        "\n",
        "            # Evaluate individuals\n",
        "            num_cnn1, f_cnn1, accuracy_cnn1, params_cnn1 = training('1', device1, cnn1, num_epochs, loss_func,\n",
        "                                                                    train_dl, test_dl, lr, w, max_params)\n",
        "            offspring.append([c1, f_cnn1, accuracy_cnn1, params_cnn1])\n",
        "\n",
        "            num_cnn2, f_cnn2, accuracy_cnn2, params_cnn2 = training('2', device1, cnn2, num_epochs, loss_func,\n",
        "                                                                    train_dl, test_dl, lr, w, max_params)\n",
        "            offspring.append([c2, f_cnn2, accuracy_cnn2, params_cnn2])\n",
        "\n",
        "    # Replacement with elitism\n",
        "    pop = pop + offspring\n",
        "    pop.sort(reverse=True, key=lambda x: x[1])\n",
        "    pop = pop[:N]\n",
        "\n",
        "    leader = max(pop, key=lambda x: x[1])\n",
        "    bestAcc.append(leader[2])\n",
        "    bestF.append(leader[1])\n",
        "    bestParams.append(leader[3])\n",
        "\n",
        "    print('Best fitness: ', leader[1])\n",
        "    print('Best accuracy: ', leader[2])\n",
        "    print('Best No. of Params: ', leader[3])\n",
        "    print('No. of Conv. Layers: ', leader[0].n_conv)\n",
        "    print('No. of FC Layers: ', leader[0].n_full)\n",
        "    print('--------------------------------------------')\n",
        "\n",
        "results = pd.DataFrame(list(zip(bestAcc, bestF, bestParams)), columns=[\n",
        "                       'Accuracy', 'Fitness', 'No. Params'])\n",
        "final_networks = []\n",
        "final_connections = []\n",
        "objects = []\n",
        "for member in pop:\n",
        "    p = member[0]\n",
        "    objects.append(p)\n",
        "    n_conv = p.n_conv\n",
        "    n_full = p.n_full\n",
        "    description = 'The network has ' + \\\n",
        "        str(n_conv) + ' convolutional layers ' + 'with: '\n",
        "    for i in range(n_conv):\n",
        "        nfilters = str(p.first_level[i]['nfilters'])\n",
        "        fsize = str(p.first_level[i]['fsize'])\n",
        "        pool = str(p.first_level[i]['pool'])\n",
        "        psize = str(p.first_level[i]['psize'])\n",
        "        layer = '(' + nfilters + ', ' + fsize + \\\n",
        "            ', ' + pool + ', ' + psize + ') '\n",
        "        description += layer\n",
        "    description += 'and '\n",
        "    description += str(n_full)\n",
        "    description += ' '\n",
        "    description += 'fully-connected layers with: '\n",
        "    for i in range(n_conv, n_conv+n_full):\n",
        "        neurons = str(p.first_level[i]['neurons'])\n",
        "        layer = '(' + neurons + ')'\n",
        "        description += layer\n",
        "    description += ' neurons'\n",
        "    final_networks.append(description)\n",
        "\n",
        "    connections = ''\n",
        "    for bit in p.second_level:\n",
        "        if bit == 1:\n",
        "            connections += 'one - '\n",
        "        if bit == 0:\n",
        "            connections += 'zero - '\n",
        "    final_connections.append(connections)\n",
        "\n",
        "\n",
        "final_population = pd.DataFrame(list(zip(final_networks, final_connections)), columns=[\n",
        "                                'Network Architecture', 'Connections'])\n",
        "\n",
        "'''Saving Results as CSV'''\n",
        "final_population.to_csv('final_population.csv', index=False)\n",
        "results.to_csv('results.csv', index=False)\n",
        "stop = timeit.default_timer()\n",
        "execution_time = (stop-start)/3600\n",
        "print(\"Execution time: \", execution_time)\n",
        "\n",
        "# Saving objects\n",
        "\n",
        "with open('cnns.pkl', 'wb') as output:\n",
        "    pickle.dump(objects, output, pickle.HIGHEST_PROTOCOL)\n",
        "    output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-w0gY20isaY"
      },
      "outputs": [],
      "source": [
        "# !cp final_population.csv /content/gdrive/MyDrive/Ricardo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_KxIgYQkFs3"
      },
      "outputs": [],
      "source": [
        "# !cp result.csv /content/gdrive/MyDrive/Ricardo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCk9-7bUkLhH"
      },
      "outputs": [],
      "source": [
        "# !cp cnns.pkl /content/gdrive/MyDrive/Ricardo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "hqh1fTflGHK4",
        "outputId": "7e428c5e-546e-46a1-840d-c9130c9e84a2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJXgj7AOV2OT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "model = pickle.load(open(\"cnns.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep7abBCVWhe-"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "I/O operation on closed file.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[219], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m final_connections \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m objects \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m      5\u001b[0m     p \u001b[38;5;241m=\u001b[39m member\n\u001b[1;32m      6\u001b[0m     objects\u001b[38;5;241m.\u001b[39mappend(p)\n",
            "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
          ]
        }
      ],
      "source": [
        "\n",
        "final_networks = []\n",
        "final_connections = []\n",
        "objects = []\n",
        "for member in output:\n",
        "    p = member\n",
        "    objects.append(p)\n",
        "    n_conv = p.n_conv\n",
        "    n_full = p.n_full\n",
        "    description = 'The network has ' + str(n_conv) + ' convolutional layers ' + 'with: '\n",
        "    for i in range(n_conv):\n",
        "        nfilters = str(p.first_level[i]['nfilters'])\n",
        "        fsize = str(p.first_level[i]['fsize'])\n",
        "        pool = str(p.first_level[i]['pool'])\n",
        "        psize = str(p.first_level[i]['psize'])\n",
        "        layer = '(' + nfilters + ', ' + fsize + ', ' + pool + ', ' + psize + ') '\n",
        "        description += layer\n",
        "    description += 'and '\n",
        "    description += str(n_full)\n",
        "    description += ' '\n",
        "    description += 'fully-connected layers with: '\n",
        "    for i in range(n_conv, n_conv+n_full):\n",
        "        neurons = str(p.first_level[i]['neurons'])\n",
        "        layer = '(' + neurons + ')'\n",
        "        description += layer\n",
        "    description += ' neurons'\n",
        "    final_networks.append(description)\n",
        "\n",
        "    connections = ''\n",
        "    for bit in p.second_level:\n",
        "        if bit == 1:\n",
        "            connections += 'one - '\n",
        "        if bit == 0:\n",
        "            connections += 'zero - '\n",
        "    final_connections.append(connections)\n",
        "\n",
        "\n",
        "#final_population = pd.DataFrame(list(zip(final_networks, final_connections)), columns = ['Network Architecture', 'Connections'])\n",
        "\n",
        "'''Saving Results as CSV'''\n",
        "#final_population.to_csv('final_population.csv', index = False)\n",
        "#results.to_csv('results.csv', index = False)\n",
        "#stop = timeit.default_timer()\n",
        "#execution_time = (stop-start)/3600\n",
        "#print(\"Execution time: \", execution_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s6zz8ujYLKw"
      },
      "outputs": [],
      "source": [
        "final_networks"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
