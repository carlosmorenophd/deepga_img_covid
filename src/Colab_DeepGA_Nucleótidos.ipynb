{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWXiuMYzYJIk"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "laZjSYBuYLER"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "import scipy.io\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz3PivL1ZjNq"
      },
      "source": [
        "**Operators.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "7KRbWus4ZldZ"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def crossover(x, y):\n",
        "    x = deepcopy(x)\n",
        "    y = deepcopy(y)\n",
        "\n",
        "    '''First parent'''\n",
        "    x_nconv = x.n_conv\n",
        "    x_nfull = x.n_full\n",
        "    xblocks = x.first_level\n",
        "    xbinary = x.second_level\n",
        "\n",
        "    '''Second parent'''\n",
        "    y_nconv = y.n_conv\n",
        "    y_nfull = y.n_full\n",
        "    yblocks = y.first_level\n",
        "    ybinary = y.second_level\n",
        "\n",
        "    '''Convolutional part crossover'''\n",
        "    if x_nconv > y_nconv:\n",
        "        k = math.floor(y_nconv/2)\n",
        "        index = list(range(x_nconv))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(k, y_nconv):\n",
        "            block = yblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            yblocks[i] = xblocks[ix]\n",
        "            xblocks[ix] = block\n",
        "\n",
        "    if y_nconv > x_nconv:\n",
        "        k = math.floor(x_nconv/2)\n",
        "        index = list(range(y_nconv))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(k, x_nconv):\n",
        "            block = xblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            xblocks[i] = yblocks[ix]\n",
        "            yblocks[ix] = block\n",
        "\n",
        "    if x_nconv == y_nconv:\n",
        "        k = math.floor(x_nconv/2)\n",
        "        index = list(range(x_nconv))\n",
        "\n",
        "        x_part = xblocks[k:x_nconv]\n",
        "\n",
        "        '''Exchaning last half of the blocks'''\n",
        "        xblocks[k:x_nconv] = yblocks[k:y_nconv]\n",
        "        yblocks[k:y_nconv] = x_part\n",
        "\n",
        "    '''Fully-connected part'''\n",
        "    if x_nfull > y_nfull:\n",
        "        k = math.floor(y_nfull/2)\n",
        "        index = list(range(x_nconv, x_nconv + x_nfull))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(y_nconv + k, y_nconv + y_nfull):\n",
        "            block = yblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            yblocks[i] = xblocks[ix]\n",
        "            xblocks[ix] = block\n",
        "\n",
        "    if y_nfull > x_nfull:\n",
        "        k = math.floor(x_nfull/2)\n",
        "        index = list(range(y_nconv, y_nconv + y_nfull))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(x_nconv + k, x_nconv + x_nfull):\n",
        "            block = xblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            xblocks[i] = yblocks[ix]\n",
        "            yblocks[ix] = block\n",
        "\n",
        "    if x_nfull == y_nfull:\n",
        "        k = math.floor(x_nfull/2)\n",
        "\n",
        "        x_part = xblocks[x_nconv + k:x_nconv + x_nfull]\n",
        "        '''Exchaning last half of the blocks'''\n",
        "        xblocks[x_nconv + k:x_nconv + x_nfull] = yblocks[y_nconv + k:y_nconv + y_nfull]\n",
        "        yblocks[y_nconv + k:y_nconv + y_nfull] = x_part\n",
        "\n",
        "    '''Second level'''\n",
        "    if len(xbinary) > len(ybinary):\n",
        "        if len(ybinary) > 1 :\n",
        "            k = random.choice(list(range(1, len(ybinary))))\n",
        "            partition = ybinary[k:]\n",
        "            nbits = len(partition)\n",
        "\n",
        "            if random.uniform(0,1) >= 0.5:\n",
        "                ybinary[k:] = xbinary[len(xbinary) - nbits:len(xbinary)]\n",
        "                xbinary[len(xbinary) - nbits:len(xbinary)] = partition\n",
        "            else:\n",
        "                ybinary[k:] = xbinary[:nbits]\n",
        "                xbinary[:nbits] = partition\n",
        "\n",
        "    if len(ybinary) > len(xbinary):\n",
        "        if len(xbinary) > 1 :\n",
        "            k = random.choice(list(range(len(xbinary))))\n",
        "            partition = xbinary[k:]\n",
        "            nbits = len(partition)\n",
        "\n",
        "            if random.uniform(0,1) >= 0.5:\n",
        "                xbinary[k:] = ybinary[len(ybinary) - nbits:len(ybinary)]\n",
        "                ybinary[len(ybinary) - nbits:len(ybinary)] = partition\n",
        "            else:\n",
        "                xbinary[k:] = ybinary[:nbits]\n",
        "                ybinary[:nbits] = partition\n",
        "\n",
        "    if len(xbinary) == len(ybinary):\n",
        "        if len(xbinary) > 1 :\n",
        "            k = random.choice(list(range(len(xbinary))))\n",
        "            partition = xbinary[k:]\n",
        "\n",
        "            xbinary[k:] = ybinary[k:]\n",
        "            ybinary[k:] = partition\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def mutation(x):\n",
        "    if random.uniform(0,1) < 0.5:\n",
        "        '''Adding a new block'''\n",
        "        if random.uniform(0,1) > 0.5:\n",
        "            #Adding a fully-connected block\n",
        "            layer = {'type' : 'fc',\n",
        "                     'neurons' : random.choice(NEURONS)}\n",
        "\n",
        "            #Choosing a random index to insert the new block\n",
        "            index = list(range(x.n_conv, x.n_conv + x.n_full))\n",
        "            ix = random.choice(index)\n",
        "\n",
        "            x.first_level.insert(ix, layer)\n",
        "            x.n_full += 1\n",
        "\n",
        "        else:\n",
        "            #Adding a convolutional block\n",
        "            layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "            #Choosing a random index to insert the new block\n",
        "            index = list(range(x.n_conv))\n",
        "            ix = random.choice(index)\n",
        "\n",
        "            x.first_level.insert(ix, layer)\n",
        "            x.n_conv += 1\n",
        "\n",
        "            if ix > 1:\n",
        "                new_bits = []\n",
        "                for i in range(ix - 1):\n",
        "                    new_bits.append(random.choice([0,1]))\n",
        "                pos = int(0.5*(ix**2) - 1.5*(ix) + 1)\n",
        "                start = pos + len(new_bits)\n",
        "                for bit in new_bits:\n",
        "                    x.second_level.insert(pos, bit)\n",
        "                    pos += 1\n",
        "\n",
        "                rest = x.n_conv - ix - 1\n",
        "                add = ix\n",
        "                for j in range(rest):\n",
        "                    x.second_level.insert(start+add-1, random.choice([0,1]))\n",
        "                    start += add\n",
        "                    ix += 1\n",
        "\n",
        "            if ix == 0 or ix == 1:\n",
        "                if x.n_conv - 1 == 2:\n",
        "                    x.second_level.append(random.choice([0,1]))\n",
        "                else:\n",
        "                    add = 0\n",
        "                    for i in range(2, x.n_conv):\n",
        "                        pos = int(0.5*(ix**2) - 1.5*(ix) + 1) + add\n",
        "                        x.second_level.insert(pos, random.choice([0,1]))\n",
        "                        add += 1\n",
        "\n",
        "    else:\n",
        "        '''Changing hyperparameters in one block'''\n",
        "        if random.uniform(0,1) > 0.5:\n",
        "            '''Re-starting a fully-connected block'''\n",
        "            index = list(range(x.n_conv, x.n_conv + x.n_full))\n",
        "            ix = random.choice(index)\n",
        "            new_layer = {'type' : 'fc',\n",
        "                         'neurons' : random.choice(NEURONS)}\n",
        "            #Switching fully-connected block\n",
        "            x.first_level[ix] = new_layer\n",
        "\n",
        "        else:\n",
        "            '''Re-starting a convolutional block'''\n",
        "            index = list(range(x.n_conv))\n",
        "            ix = random.choice(index)\n",
        "            new_layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "\n",
        "            #Switching convolutional block\n",
        "            x.first_level[ix] = new_layer\n",
        "\n",
        "        '''Modifying connections in second level'''\n",
        "        if len(x.second_level) > 0:\n",
        "            k = random.choice(list(range(len(x.second_level))))\n",
        "            #Flipping one bit in the second level\n",
        "            if x.second_level[k] == 1:\n",
        "                x.second_level[k] = 0\n",
        "            else:\n",
        "                x.second_level[k] = 1\n",
        "\n",
        "\n",
        "def selection(tournament, style):\n",
        "    '''Stochastic tournament selection'''\n",
        "    if style == 'max':\n",
        "        if random.uniform(0,1) <= 0.8:\n",
        "            p = max(tournament, key = lambda x: x[1])\n",
        "        else:\n",
        "            p = random.choice(tournament)\n",
        "    else:\n",
        "        if random.uniform(0,1) <= 0.8:\n",
        "            p = min(tournament, key = lambda x: x[1])\n",
        "        else:\n",
        "            p = random.choice(tournament)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjVfGIiqZVKh"
      },
      "source": [
        "**EncodingClass.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "-eXaGfTqZX0B"
      },
      "outputs": [],
      "source": [
        "'''Hyperparameters configuration'''\n",
        "#Convolutional layers\n",
        "'''Hyperparameters configuration'''\n",
        "#Convolutional layers\n",
        "FSIZES = [2,3,4,5,6]\n",
        "#FSIZES = [2,3,4,5,6,7,8]\n",
        "NFILTERS = [2,4,8,16,32]\n",
        "\n",
        "#Pooling layers\n",
        "PSIZES = [2,3,4,5]\n",
        "PTYPE = ['max', 'avg']\n",
        "\n",
        "#Fully connected layers\n",
        "NEURONS = [4,8,16,32,64,128]\n",
        "\n",
        "class Encoding:\n",
        "    def __init__(self, minC, maxC, minF, maxF):\n",
        "        self.n_conv = random.randint(minC, maxC)\n",
        "        self.n_full = random.randint(minF, maxF)\n",
        "\n",
        "\n",
        "        '''First level encoding'''\n",
        "        self.first_level = []\n",
        "\n",
        "        #Feature extraction part\n",
        "        for i in range(self.n_conv):\n",
        "            layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "            self.first_level.append(layer)\n",
        "\n",
        "        #Fully connected part\n",
        "        for i in range(self.n_full):\n",
        "            layer = {'type' : 'fc',\n",
        "                     'neurons' : random.choice(NEURONS)}\n",
        "\n",
        "            self.first_level.append(layer)\n",
        "\n",
        "\n",
        "        '''Second level encoding'''\n",
        "        self.second_level = []\n",
        "        prev = -1\n",
        "        for i in range(self.n_conv):\n",
        "            if prev < 1:\n",
        "                prev += 1\n",
        "            if prev >= 1:\n",
        "                for _ in range(prev-1):\n",
        "                    self.second_level.append(random.choice([0,1]))\n",
        "                prev += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFC3Jg0HL7Hk"
      },
      "source": [
        "**Decondig.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "UnLkivWFZc1j"
      },
      "outputs": [],
      "source": [
        "def conv_out_size(W, K):\n",
        "    return W - K + 3\n",
        "\n",
        "def pool_out_size(W, K):\n",
        "    return math.floor((W - K)/2) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ROxmA9hnZekJ"
      },
      "outputs": [],
      "source": [
        "def decoding(encoding):\n",
        "  n_conv = encoding.n_conv\n",
        "  n_full = encoding.n_full\n",
        "  first_level = encoding.first_level\n",
        "  second_level = encoding.second_level\n",
        "\n",
        "  features = []\n",
        "  classifier = []\n",
        "  in_channels = 1\n",
        "  out_size = 92\n",
        "  prev = -1\n",
        "  pos = 0\n",
        "  o_sizes = []\n",
        "  for i in range(n_conv):\n",
        "    layer = first_level[i]\n",
        "    n_filters = layer['nfilters']\n",
        "    f_size = layer['fsize']\n",
        "    pad = 1\n",
        "    if f_size > out_size:\n",
        "        f_size = out_size - 1\n",
        "    if i == 0 or i == 1:\n",
        "      if layer['pool'] == 'off':\n",
        "        operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                    nn.BatchNorm2d(n_filters),\n",
        "                    nn.ReLU(inplace = True)]\n",
        "        in_channels = n_filters\n",
        "        out_size = conv_out_size(out_size, f_size)\n",
        "        o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'avg':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.AvgPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'max':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.MaxPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "    else:\n",
        "      connections = second_level[pos:pos+prev]\n",
        "      for c in range(len(connections)):\n",
        "        if connections[c] == 1:\n",
        "          in_channels += o_sizes[c][1]\n",
        "\n",
        "      if layer['pool'] == 'off':\n",
        "        operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                    nn.BatchNorm2d(n_filters),\n",
        "                    nn.ReLU(inplace = True)]\n",
        "        in_channels = n_filters\n",
        "        out_size = conv_out_size(out_size, f_size)\n",
        "        o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'avg':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.AvgPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'max':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.MaxPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      pos += prev\n",
        "    prev += 1\n",
        "\n",
        "    features.append(operation)\n",
        "  in_size = out_size*out_size*in_channels\n",
        "  for i in range(n_conv,(n_conv + n_full)):\n",
        "    layer = first_level[i]\n",
        "    n_neurons = layer['neurons']\n",
        "    classifier += [nn.Linear(in_size, n_neurons)]\n",
        "    classifier += [nn.ReLU(inplace = True)]\n",
        "    in_size = n_neurons\n",
        "\n",
        "  ##Last layer generates the last neurons for softmax (change this for binary classification)\n",
        "  classifier += [nn.Linear(n_neurons, 6)]\n",
        "\n",
        "  return features, classifier, o_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Hrs1qc3JZhcF"
      },
      "outputs": [],
      "source": [
        "'''Networks class'''\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, encoding, features, classifier, sizes, init_weights = True):\n",
        "    super(CNN, self).__init__()\n",
        "    extraction = []\n",
        "    for layer in features:\n",
        "      extraction += layer\n",
        "    self.extraction = nn.Sequential(*extraction)\n",
        "    self.classifier = nn.Sequential(*classifier)\n",
        "    self.features = features\n",
        "    self.second_level = encoding.second_level\n",
        "    self.sizes = sizes\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''Feature extraction'''\n",
        "    prev = -1\n",
        "    pos = 0\n",
        "    outputs = {}\n",
        "    features = self.features\n",
        "    #print(x.shape)\n",
        "    for i in range(len(features)):\n",
        "      #print('Layer: ', i)\n",
        "      if i == 0 or i == 1:\n",
        "        x = nn.Sequential(*features[i])(x)\n",
        "        outputs[i] = x\n",
        "        #print(x.shape)\n",
        "\n",
        "      else:\n",
        "        connections = self.second_level[pos:pos+prev]\n",
        "        for c in range(len(connections)):\n",
        "          if connections[c] == 1:\n",
        "            skip_size = self.sizes[c][0] #Size comming from previous layer\n",
        "            req_size = x.shape[2] #Current feature map size\n",
        "            #print('X: ',x.shape)\n",
        "            if skip_size > req_size:\n",
        "              psize = skip_size - req_size + 1\n",
        "              pool = nn.MaxPool2d(kernel_size = psize, stride = 1) #Applying pooling to adjust sizes\n",
        "              x2 = pool(outputs[c])\n",
        "            if skip_size == req_size:\n",
        "              x2 = outputs[c]\n",
        "            if req_size == skip_size + 1:\n",
        "              pool = nn.MaxPool2d(kernel_size = 2, stride = 1, padding = (1,1))\n",
        "              x2 = pool(outputs[c])\n",
        "            if req_size == skip_size + 2:\n",
        "              pad = int((req_size - skip_size)/2)\n",
        "              padding = nn.ZeroPad2d(pad)\n",
        "              x2 = padding(outputs[c])\n",
        "            #print('X2: ',x2.shape)\n",
        "            x = torch.cat((x, x2), axis = 1)\n",
        "\n",
        "        x = nn.Sequential(*features[i])(x)\n",
        "        #print('Out size: ', x.shape)\n",
        "        outputs[i] = x\n",
        "        pos += prev\n",
        "\n",
        "      prev += 1\n",
        "\n",
        "    #print('Classification size: ', x.shape)\n",
        "    x = torch.flatten(x,1)\n",
        "    '''Classification'''\n",
        "    '''for l in self.classifier:\n",
        "      x = l(x)'''\n",
        "    x = self.classifier(x)\n",
        "    # return x\n",
        "    #print(x.shape)\n",
        "    return nn.functional.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4e6T3hPGi01"
      },
      "source": [
        "**DataReader.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "7byf3HzsZOjR"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.labels = []  # Lista de etiquetas de clase\n",
        "        self.datos = []\n",
        "        file_csv = os.path.join(\n",
        "            root_dir, \"dataset_to_deepga.csv\")\n",
        "        data = np.loadtxt(file_csv, delimiter=',', skiprows=0)\n",
        "        # Removemos la última columnas\n",
        "        label = data[:, -1]  # Obtenemos la clase\n",
        "        self.labels = label.astype(int)\n",
        "        self.datos = data[:, :-1]  # Obtenemos los datos\n",
        "        # Sección para agregar 26 columnas con la finalidad de realizar el reshape\n",
        "        # tam = data.shape[0];\n",
        "        # complemento = np.zeros((tam,26))\n",
        "        # self.datos = np.concatenate([complemento, data], axis=1)\n",
        "        # self.datos = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = self.datos[idx]\n",
        "        # vect2 = np.zeros(26, dtype=float)\n",
        "        # image = np.concatenate([vect2, image], axis=None)\n",
        "        # Redimensionar la imagen a 92\n",
        "        image = np.array(image)\n",
        "        # print(image.shape)\n",
        "        image = image.reshape(92, 92)\n",
        "        [H, W] = image.shape\n",
        "        image = image.reshape((H, W, -1))\n",
        "        # print(image)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        sample = {\"image\": image, \"label\": label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample[\"image\"], sample[\"label\"]\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {\"image\": torch.from_numpy(image), \"label\": label}\n",
        "\n",
        "\n",
        "def loading_data():\n",
        "    root_dir = '../data_img_test'\n",
        "    custom_dataset = CustomDataset(\n",
        "        root_dir=root_dir, transform=transforms.Compose([ToTensor()]))\n",
        "\n",
        "    train_size = int(0.7 * len(custom_dataset))\n",
        "    test_size = len(custom_dataset) - train_size\n",
        "\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        custom_dataset, [train_size, test_size])\n",
        "    # print('Custom datset size : ', len(custom_dataset))\n",
        "    # print('Data size training: ', len(train_dataset))\n",
        "    # print('Data size test: ', len(test_dataset))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=30, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=30, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVmaNMkuLBNN",
        "outputId": "dd09f578-ac25-4dfe-b398-7da8df63ab5a"
      },
      "outputs": [],
      "source": [
        "train_dl, test_dl = loading_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "mZ1DCHUPMPry"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 1, 92, 92])\n",
            "tensor([3, 3, 2, 5, 4, 5, 3, 4, 3, 3, 3, 1, 3, 0, 3, 4, 3, 4, 5, 2, 1, 4, 4, 5,\n",
            "        0, 2, 1, 4, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Dimensiones del tensor test\"\"\"\n",
        "for i_batch,sample_batched in enumerate(test_dl):\n",
        "  print(sample_batched['image'].shape)\n",
        "  print(sample_batched['label'])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "ieYKLeNBMWLx",
        "outputId": "c1805557-884c-42ab-f67d-029cf96ec6bc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAYAAADsNrNZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+EUlEQVR4nO3de3DV9Z3/8TcQCLcQICEnCSQQMcpVuUOA6WpltC3dRWV0neIuvUzdtsGKzNRKt7BbW4zanZbVpbo6XWpnpW7Zqdq1s1onKo5yFRVFJaBQiUrCNTnIJWDy/f3RH2f5PM9pPh5un3OS12OGmb5zTs75nu/5Hj89n1fen0+XKIoiExERucC6hj4AERHpnDQAiYhIEBqAREQkCA1AIiIShAYgEREJQgOQiIgEoQFIRESC0AAkIiJBaAASEZEgNACJiEgQ520AWrFihQ0bNsx69uxpU6dOtY0bN56vpxIRkSzU5XysBfdf//Vf9vd///f20EMP2dSpU2358uW2evVqq6urs6KionZ/t62tzT7++GPLy8uzLl26nOtDExGR8yyKIjt8+LCVlpZa167tfM+JzoMpU6ZE1dXVibq1tTUqLS2NampqvL9bX18fmZn+6Z/+6Z/+Zfm/+vr6dv97n2Pn2IkTJ2zz5s22ePHixM+6du1qs2bNsnXr1iXdv6WlxVpaWhJ19P+/kNXX11u/fv3O9eFlhNbWVqc+fPiwU3/88cdOvXXr1nZ/f8CAAU7dq1cvp+7fv79TFxQUOHVhYWHSMfbs2TPpZ/LZ8T2tr693ar6Hn376qVPz2z9vP/0zk+rxeHvfvn2dety4cU7Na0bkbMTjcSsrK7O8vLx273fOB6D9+/dba2urxWIx5+exWMy2bduWdP+amhr70Y9+lPTzfv36dZoBiP+xicfjTt27d2+n5n+MeDtr/seHF0Wq86wB6OzwPeV7kO4AdPLkSafOyXE/unw83t6nTx+n5nuuAUjOB1+Mcs4HoHQtXrzYFi1alKhPjZzZLEKs1tjY6NTvvfeeU+/bt8+p9+7d69T8f7N8U/fv3+/U/I9PW1ubU584ccKp+Q3JzGzChAlOPXHixHaPobPbvXu3U7/44otOzfe0R48eTs0Bn/8ngvgeduvWrd2a36pZX3LJJU49duzYdh9P5Fw45wNQYWGhdevWLek/uo2NjVZcXJx0/9zcXMvNzT3XhyEiIhnunP8Zdo8ePWzixIlWW1ub+FlbW5vV1tZaVVXVuX46ERHJUudlCm7RokU2f/58mzRpkk2ZMsWWL19uR44csa997Wvn4+lERCQLnZcB6G//9m9t3759tnTpUmtoaLBx48bZM888k/SHCR3Vhx9+6NR1dXVO/dFHHzk15+P5F1R0/Phxp+bf2TOQZgbEwLmpqSnpOf70pz859dtvv+3UN910k1N3tmlU/kHNqlWrnPqTTz5xap4fZioDBw50auZ4vCb4njInzM/Pd2pOf3fv3t2pd+3a5dS8pkaPHu3UyoTkXDhvf4SwYMECW7Bgwfl6eBERyXJaC05ERILQACQiIkEE7wPqCJj5cOWCzZs3OzUzH+YF7BHhfD/7jDj/z74iNkHy8VPN57NRccuWLU7N3qHZs2c7NTOMbHfw4EGnXr16tVMfOnTIqZmxMLdrbm52al4TzIT4Hh85csSp2RfE+3O1jEsvvdSpR40a5dQNDQ1OzdczcuRIEzlb+gYkIiJBaAASEZEgNACJiEgQHWui/gLZs2ePU69du9ap169f79Rcq42YwXC+nX09xHyCeQPzGOYDzJTMkvtOBg0a5NQbNmxwamYMn/vc59o54szHc/Lss886NTMYLvDK94TXAH+fa+sxU+L55zXBa4jvOY/nlVdecWr2AU2bNs2puYI6rzEtXitnQt+AREQkCA1AIiIShAYgEREJQhnQZ8DM57nnnnNqrpvG+X1uBsb5eWY+nE/nfDv7gpg/ML9gHxBv52ZoqX7GTIgbpK1Zs8apL7roIqceMmRI0nNksk2bNjn1+++/79Tsk+KOp9z/h+fr2LFjTs1rgL1aXJuNt/P3ud7f0aNHrT3MBZlBMWPi/kfcw0sb3MlnoW9AIiIShAYgEREJQgOQiIgEoQwoBa6rxR4JruPFnozevXs7NXs8mOEwb+F8PfMCHh8zIs7nM3NixsT8INV9+Bg8Zu5x9Oqrrzr14MGDnZrnJDSux8e175izvfvuu07NHJAZCH/f9x7wdp4vnn9eg8ycfH07w4cPd+qKigqn5vnh8bDPiZlfpr3fkhn0DUhERILQACQiIkFoABIRkSCUAVlyJsO+n9zcXKcuKSlx6qamJqdmRsT5d9bMfDg/z74dzvcz8+FeLsyk2EPC12eWvN8PMw3fY77++utOPX78eKceOnRo0nNeSDyn3MOJfTfs82Hmxfsz82AfTWFhoVOnm+nwGuM1xGuMxzd27FinLioqcmpe0779nZhTsveMawWKmOkbkIiIBKIBSEREgtAAJCIiQSgDsuR1zg4cOODUnF9nTwfzEM6/x+Nxp+Z8PjMo9vn4cK05zr/z8Vhz/j7Vz/Lz852auRGPgefgrbfecury8nKnvtB9InxPuPYZa2Y+zMiIGRPPBzMcZmi+3jGef2ZGzJh4vktLS52anwEeP68ZPh/ff+aYPF/qCxIzfQMSEZFANACJiEgQGoBERCSITpkBcT6de71wLxf2RLDvJhaLOfVll13m1FwnjOtmcX7d13Ph6xPiXjUHDx50avac8HyYJa9NxlyMj8E+IZ6T7du3O/XMmTOd2pepnGvMuFjzPeL54PHyPeQ1xN6y4uJip2aGUlBQ4NS85oi9ab619/h4vJ3XFHvL+P6zz4iZEo+P14d0TvoGJCIiQWgAEhGRIDQAiYhIEJ0yA2KPx2uvvebUzEzYA8M8gPPfnN/mfD7zlMbGRqfm3ivsuWBGxJp5DDMh9qCk6gPia2TGceTIEadmjsZeKfa5fPjhh059oTMgZhx8PXy97KthLxfPIXvHeA3x+blWHM8/MxSurcYMia+Hx8s+ImZCzD2Jx8fH5/v7wgsvOPWNN97o1PwMSeegd11ERILQACQiIkFoABIRkSA6ZQb09ttvO/UHH3zg1JyP5nz3wIEDnZr5BvtqON8/aNAgp2b+wfl3Zlacr+fj8/m5NhxfD9cpM0te3459H8zJ2Pexe/dup2YGwoxgzJgxScdwPrGXin0wzFSY8ezbt8+pmdvxPSE+H/uCLrnkEqdmjsiMitcEr2G+nzxevp/MiJjp+TJCni++3+yT4uuXzkHfgEREJAgNQCIiEoQGIBERCaJTZEDMRLi3CzMS9tFwPp+ZDB+ffTnMWNgjwsdnPsD8hH1B/H3mNXy+VGu/EXMt4n4yzK3Yh8La12dyvjEDYs0+G/ZOEXNBXlN8/KKiIqdmLsgMhhkL32OeX2Y6XNuO9+c1x74nX6bE3/dlRlwfURlQ56RvQCIiEoQGIBERCUIDkIiIBNEpMiD2PHA+m/P9zGyY+TAP4ONzPpzz5cxsfD0pvrXhmBfw9TGTYibEdchSHYMvI2CmwT4gnkPfnkfnm2//Iu7fw3PKzIKvh+vvpeq1Oh0zHV4jfM94fj/++GOn5vnme8xMicfL95vXPM8HM0OeH55frh3HXFJrw3UOepdFRCQIDUAiIhKEBiAREQmiU2RAnH/39ViwT4h5AOfrOV/N+Wyui8V104iZFOfn053P92VWvnXLUj0m+zzIt78P+15CY6bFc8TMiJkPMxNeI76MhWu5MfNh3wyvSeaCvCb4HvMzwD4dPh6vaWY4vv2VeH++/7y/7/qSjkHfgEREJAgNQCIiEoQGIBERCaJTZEBcd4yZyM6dO9u9P+e/mSlx/pzz+5wfZ57ATIgZFNfx4vP51t1ivsD5/1R9QHzNzAS41hhzMD4m+0J8GdGFVlZW5tTsW+Hr43vKTIjnj30y7NNh5sRr1HcN8/0hZkJ8fbwGeQ35sJeNr5/7//Azd/nllzu1MqDOQd+AREQkCA1AIiIShAYgEREJolNkQPX19U7NjIXz1ezh4Px9nz59nNqXBzAPYU+ELx9gpsT5fuYB7CHh3jR8/lTrbvn6RFgzQ+A5rKiocGrmYKHxHI0fP96pX3nlFadmJsPXy0wnHo87Na+ZgoICp+Y1xmuA55t7RvH18Jrk+8vH5zWR7u18fax5PrZv3+7U2h+oc9A3IBERCUIDkIiIBKEBSEREguiQGRAzjl27djm1b+009jRwfp+ZEdexYp8QMx5mOMyIOF/P1+NbC863zhj3J+LtZsmviTiHz+dkhtHY2NjuMWSakpISp2Zm9dprrzk1MxlmQFzfj2vP8ZpiRsP9lvj+MJNhHw2vKV7TfD5eo/xM8PGYCfL+PB5ew1zbTjoHfQMSEZEgNACJiEgQGoBERCSIDpkBHThwwKn37dvn1OyZYH7B+XvW3N+HGQ3n57lumm//HeYB7Dkhzqf7Hp/z85z/T3UMvjl8ZgDMpXgOeQyZhsfH42fOx0yE1xhrroXH94wZDZ/Pl+MxE+LtvrXbfO8vrxnfNcdMkJkan9+3fqF0DPoGJCIiQWgAEhGRIDQAiYhIEB0yA+JaaL69Zzi/TsxwuD8PMyHmBb4+It9eM76MihmUb36dPSmDBg0y8mUE7J3iMXItMmZImZ4B8fgHDx7cbs33gJkQMePw7b/ky1x8+wkx0+H7xefn+8PfZ6bDjIhr2/Ezwvvz+Jl7cv8i6Rj0DUhERILQACQiIkGkNQDV1NTY5MmTLS8vz4qKiuzaa6+1uro65z7Hjx+36upqKygosL59+9rcuXOTlmERERFJKwNas2aNVVdX2+TJk+3TTz+1H/zgB3b11VfbO++8k5gTvv322+0Pf/iDrV692vLz823BggV2/fXXJ+2ncj5x/pzz1ZwfZ58Q969nRsTH51pvvvl6ZkLMC5gJcb6ceH/O5/uOn31TZsmvgY/h2w+Gvz9s2DCnzvQMiO8JryGeQ/bl8HwNHTrUqbl23M6dO52amdLAgQOdmrkkMxTf2m6+9QiJ1zivGd81zwzIl0Oyj0w6prQGoGeeecapf/WrX1lRUZFt3rzZPve5z1lzc7P98pe/tFWrVtnnP/95MzNbuXKljRw50tavX2/Tpk07d0cuIiJZ7awyoFPfJE79v7PNmzfbyZMnbdasWYn7jBgxwsrLy23dunUpH6OlpcXi8bjzT0REOr4zHoDa2tps4cKFNmPGDBszZoyZmTU0NFiPHj2S/uw5FotZQ0NDysepqamx/Pz8xL+ysrIzPSQREckiZ9wHVF1dbVu3brWXX375rA5g8eLFtmjRokQdj8fTHoQ438yMh/Pd3H+ea7f5+nDYZ8O+I18PBR+PmRDzFR5fuvPjzBP4fKkwA/F9M+U54/8JyfY5fb5nvv1yfHtAsS+KGQ/vz8yE+xUxx2SfEa8BPj4xd+T9eY2yb8p3jfP/kDIT++CDD5xa/8e0YzqjAWjBggX29NNP20svvWRDhgxJ/Ly4uNhOnDhhTU1Nzn+AGhsbrbi4OOVj5ebmaqFBEZFOKK0puCiKbMGCBfbEE0/Y888/bxUVFc7tEydOtO7du1ttbW3iZ3V1dbZ7926rqqo6N0csIiIdQlrfgKqrq23VqlX21FNPWV5eXuJrdH5+vvXq1cvy8/PtG9/4hi1atMgGDhxo/fr1s1tvvdWqqqr0F3AiIuJIawB68MEHzczsiiuucH6+cuVK++pXv2pmZj//+c+ta9euNnfuXGtpabFrrrnGfvGLX5yTg/2sOJ/M/eY5P86eDd/+OpzfJj4e57/5+L69W1j7np+P5zu+VD05PGbe59ChQ+0eE9+DkSNHOrVv/5hMw4yDfUE8X6zr6+ud2rf2G9dSo9OnvlM9H9crZE7J94t9TOTLfHi7b31DYua0e/fudu8vHUNaA9Bn+Y9Gz549bcWKFbZixYozPigREen4tBaciIgEoQFIRESC6BD7AbFP5r333mv3/uzj4TparJnZsEeGPS9c94t9SXx8n3TXdmPNHhBfj0eq5+RjcC0w9r0wY2CfCh8/2/Ac8vXwGvGdD2YwXOuNOSAzGF4TPB72GfF2Hh+vee7/lG5vG5+P54+ZGq8vfmb4+iU76RuQiIgEoQFIRESC0AAkIiJBaAASEZEgOsQfIbApkoElm+IYoHItOjZd8nbWvg3hGDAzoGbTJv8ogPfnwpS+pkbf62WTolnyHx34NmTjH4IwZGZIzcfP9PUAeY75njF05/niYqy+P0TxXYPExlQ2orKHj9eUb7FU34ZzvveX9+f1wT9i4fn96KOPnPrSSy81yX76BiQiIkFoABIRkSA0AImISBAdIgNqampyat8GbIWFhU7NRtJjx445dbqNqr4183zz6Ww69D0emwTZlMj5eeYTzAPMkjMBztEPGzbMqfke+BoPWWc6Hu+gQYOcmjkaMx/mhFycldcs8Rpm5sZrls/Ha8CXyaS74C0fj9c4c1BmTLydnwEu5qoMqGPQNyAREQlCA5CIiAShAUhERILoEBkQ58eZaXC+mfPXXCzU19PC+Xren8fjy3Q4f8/H8+UJxMVWebw8H8XFxUmPwZyIuRczIS4OydfMnC3T+36I54wZEHO3P/3pT07N3i3+Pu9/arfhU/ie+jbAI19vmq8vhzXfX981Sby+2PfE883zy88Ej0+yg74BiYhIEBqAREQkCA1AIiISRIfIgDh/zEyD89XMWJgZcb6c8/G+viP2UHB+nD027CHh8/P3eX/e7suAuNkXNz8zMysqKmr3Mdn7xHPM18jHy3apNvE7Hc8Xrznf7zPz4DXI3JB8GYmvF4yfKfJtKMfeNJ4P32fC9/i+8yfZQd+AREQkCA1AIiIShAYgEREJIiszIN/aaOxJ4Xw6M5bGxkanZkbCHhhmKr51vHz7EcViMafm/H2q/Xrauz9rzud/lp4c5li8DzMf4jn1vYZMN3jwYKfme+jb04nX3N69e52ae1qxr4fXIN8f5p68vy8z4WeKmRWvcWZGPH72PfH18BplX5Svd08ZUMegb0AiIhKEBiAREQlCA5CIiASRlRkQcX6aPQecD9+xY4dTMyPi/LJvrxL2WLBHg/kAH4/Px3yBOB/Ox/OtC8aMK1XPB5+joqLCqdmnwfX0+JjZPmefn5/v1MwomHHxmmLvGM+vL7NJd+02X2bH94eZEq9ZXpO8P4+Hz89rkueDr993fDy/zH0lO+gbkIiIBKEBSEREgtAAJCIiQWRlBsSeCuJ89549e5ya88ecj/etxcb5eF8Ph29dLeYnnO9mpsX59Xg87tR8fZyf5/Hw/mbJudr+/fudmmt9MbPgOcv2/Vp81wDX0+M1wWuQvVjMRNgnw+djJrNv3z6n5jXCPh/mgLzmWJNv7Tbi6/HdzuPjWnijRo1q9/EkO+gbkIiIBKEBSEREgtAAJCIiQWRlBsT5bM4fc/6dGQrXseK6V775b97uyzc4H888gT0mPtwbhWvJMQNjXsDXz/OT6jk4x88+EeZKfM2jR49Oeo5sNmLECKeura11al4jvGaZGfn27+H59+V8vr4j3/P59sji6+H778tRmZP6+pyYATEjKiwsNMk++gYkIiJBaAASEZEgNACJiEgQHSID4nw658c5v8z5ec5XMzNhz4tvvpnrWnG+mzV7Kjg/n+5eKty7hvh6OD9vlry2lm+PImY+zLW4P0y2u+iii5z64osvdupt27Y59cCBA52a1yDPN88n78/zz/eQz8e+Ll8vHa85X47JHNHXW0ep9qRq73jY93TppZe2+/uSmfQNSEREgtAAJCIiQWgAEhGRILIyA+J+O1ynzLe/DjMc33w5a85vcz7e1xfE+Ww+HnswfJkV1xn78MMPnZqvl7+faq06ZhLsLWLt2x+GuVO24zU1efJkp+b5YS7HPipew77cj7kmr0H2cTGD4/qBvhyUmR4zH19vHs8Hrw/W/H0eD3v3JDvpG5CIiAShAUhERILQACQiIkFkZQbE+W7OB3P+nPPXnB/fu3evU3O+2jcfzQyH8+GsmSlxPp63EzMw3p/Px/l99imlWouOv8PeKp4j8uVwHQ33p9m+fbtTc+0yrtXmW1+Q77nvGuR6iOwVY98Nc0fi8/n2A2KGyJrXHG/n4/P18xqX7KRvQCIiEoQGIBERCUIDkIiIBJGVGZCvB6V///5OzflrX98O+2I4H83Mxrd2G5/Pt64a8xY+Hl8Pj9f3evj7fD6z5Ne4c+dOp2aG4DtnqfYc6kjy8vKcmmuTbdy40akLCgqcmr1cvCbq6+udmu+x75pnJuTrw2FvnG+/H99+QXz/WfN6Ys3zy+OV7KRvQCIiEoQGIBERCUIDkIiIBNEhMiCuM8aeBt7ft/Ya+4p8fUfMUDh/zflx5iO+vVZ4f2ZevD8zJvaclJeXO3WqddqYAfl6rXhMXKuso2dAxAyIfUHE3jT2avE94h5YxPX/2CvGa4R9ObxmmFkx4+H1wIzK95nzXU88P6l61yT76BuQiIgEoQFIRESC0AAkIiJBZGUGxPlr9kCw54EZim9vGz6+bx0q1sxLfOti8fg4X88MivPlzJh4f863l5SUOHVpaanRpk2b2n1OXy42derUdo+ho2NGMW7cOKf+3e9+59Tcr4d9P+yDYe7Ivh/uL8QMzpeh8JpsbGx0amY6vKb5mWAmyM8Uj8+3HiIzIslO+gYkIiJBaAASEZEgNACJiEgQHWJinvPHzCO4309zc7NTcz6dPQecj+Z8O+ejfXvn8PGZOTHT8eUn/H3e3zffz/NhlnzMPMd8jZzTZ0bU2bH3ipkJ+a5pZkbsC2Lmwr4cZjRcW43XEPuCuDbc4cOHnZp9S/wM8Zpj3xmPh4/HTFKyk74BiYhIEBqAREQkCA1AIiISRFZkQJyvZgbDmvPl7AvyZSzsgWDPA+ezOR/Omut6cb6bj8+a8/fMD5gBFRUVOTUzIK49x+MxSz6ngwcPdmrOyR84cMCpuXZYZ8fzxb6gl156yamLi4uduq6uzql5TTDz8V1Dvv18mOnx8ZgB8pr3XdPMGH2ZDvuihg0b1u79JTvoG5CIiAShAUhERII4qwHonnvusS5dutjChQsTPzt+/LhVV1dbQUGB9e3b1+bOnZu0jIeIiMgZZ0CbNm2yf//3f7fLLrvM+fntt99uf/jDH2z16tWWn59vCxYssOuvv95eeeWVMz5IZkC+TIY9KOzTSTdTYobC+XJmTryd8+Ocr2dfEOfDeTszKz4ez4evz4n5QKrf4TllHwpzpYsvvjjpMeX/TJgwwam59h77YHjN8priNcq+IOaE/EzwGk73GuP7z9/3rV3n60viZ2Lfvn0m2e+MvgF98sknNm/ePHvkkUec/xA1NzfbL3/5S/vZz35mn//8523ixIm2cuVKW7t2ra1fvz7lY7W0tFg8Hnf+iYhIx3dGA1B1dbXNnj3bZs2a5fx88+bNdvLkSefnI0aMsPLyclu3bl3Kx6qpqbH8/PzEv7KysjM5JBERyTJpD0CPP/64vfbaa1ZTU5N0W0NDg/Xo0SNpe4RYLGYNDQ0pH2/x4sXW3Nyc+Mc/txQRkY4prQyovr7ebrvtNnvuueeS5qDPVG5ubtL8MTFT4fwx16Hi/DFr9jhwPpsZE/uCeLy++W9mLHx85ivsGfGtG0Y8H1RYWOjU7JNKdQycg+fv8Hrgc4iL/yftyiuvdOo//vGPTh2LxZyavWXM5Ph+MAPiWmy83Ydr1fH5mOn49rwiZk78TPl+X7JDWt+ANm/ebHv37rUJEyZYTk6O5eTk2Jo1a+z++++3nJwci8ViduLEiaSFCxsbG5Ma60REpHNL6xvQVVddZW+99Zbzs6997Ws2YsQI+/73v29lZWXWvXt3q62ttblz55rZnzu4d+/ebVVVVefuqEVEJOulNQDl5eXZmDFjnJ/16dPHCgoKEj//xje+YYsWLbKBAwdav3797NZbb7WqqiqbNm3auTtqERHJeud8Lbif//zn1rVrV5s7d661tLTYNddcY7/4xS/O6jE5n8weBs4HM/Px7a3CmpkN57eZj/B4OL/OmvPZzIQ4H88pTWZivr4hrsvG30/1ByLcQ4m5EnM07ddydkaOHOnU27dvd2peI++++65TM4f0ZbTMlFLtCXU6fsaYYfn2xPL1AfnWUyQ+n2Snsx6AXnzxRafu2bOnrVixwlasWHG2Dy0iIh2Y1oITEZEgNACJiEgQWbEfEPcOSbengPPNnC9nZsKMhPPNrJmHEJ/P1yPB+XK+PuYxfHzmL7z/wIEDnZrn1yx5LTEeI3Ms9v3wnEr78vLynHrs2LFOzZyS92dflm/9QF4zzPD4fpMvJ+XjM8PiZ9LX68fn4zXNa9jXWyiZQd+AREQkCA1AIiIShAYgEREJIisyIB/OVzNjYc8C15niFhDsw2Hty4g4H875b99eJrw/+4B8PRQ8Pq4bxvly9gmZJfdS8TmZIxH3p5H0XHrppU795ptvOjUzmw8//NCpmRmVlJQ4Na8B3x5WzJCIuSXxGku1B9Xp+BlId205ZUDZQd+AREQkCA1AIiIShAYgEREJIisyIM7/+taG4/wy54OZifjWYuN8uW++m304vnW2ON9+4MABp+Z8t29/IWZa/H32LaXKa5ibse/Ctx6eLyOS9vGaqKysdOo9e/Y4Na8J9nEx42HfFq9ZX98OP4PEDJGPx5qvl6/H18ck2UnfgEREJAgNQCIiEoQGIBERCSIrMyD+zT/7enh/3zpTnI/2ZT7MiNhzwePz7XXi2yvFN5/O4+Xx8PeLioqcOlVPBtca8+3BVFpa2u7vy9kZNWqUU3Nn4uHDhzs1e8d4TfAaY58Qc1Le35cZcQ8u3t/XK8ea1ygzLH7GJTvoG5CIiAShAUhERILQACQiIkFkbAYURVEiy+H8MTMe9rFw/psZCR/Pl+mwb4b5B3+f89vMT3x9Opz/Zg+EL0Pi7xNfH3t6zJJfM3MkHgMzBGYGcnb4HpWVlTk114Lj+8PPAK9Zvt+85vbv3+/UvB6Y0fCaZ0bD3JaP5+v18/XuSXbQNyAREQlCA5CIiAShAUhERILIygzIt/abb36YGRFv9+0/T5yf53w713bjfDdx/pvz5cT5dd86Wbw91V4vzBB4DMzdYrFYu88p59aYMWOcet26dU7dp08fp/ZlKOz7YR8Xr0nmjrydn1k+ni+3TLdvyLc+o2QmfQMSEZEgNACJiEgQGoBERCSIjM2APv3008Q8MOeDmVn4eg64NwozIOL8ct++fZ2afUA8Pj4+78++H1+PBDMm9hFx7x6uw8Xzw3yA9zdLfk08Br4HXF9Ozi+uhcb9l/ge8xok3s5MiI/HviFew7zmmBExJyVfhuTLpCQ76BuQiIgEoQFIRESC0AAkIiJBZGwG1NbWlphX5vyyb60z9u1wvpnzx8xkyJepNDc3t/v77Pvxre3m20uHt3PdNT4ezx/n11MdP3OzQ4cOtfucvjl9ObfYy8W1+Hbs2OHU+/btc2peg+yF4zXC5+NngNcDM0N+ZvmZO3r0aLuP77u/MqDspG9AIiIShAYgEREJQgOQiIgEkbEZ0NGjRxPz1L4eA84Hcz6b9/fNLxOf37f2Gvt4eLtv/yC+Ht98PPuUmIFxLTpfBpXqMXjMXPtNa8FdWLyGef7ZG8b9fJjJ8Jpmpsdrkusl+o6PGZFvjy8fHg9773z7CUlm0DcgEREJQgOQiIgEoQFIRESCyNgM6NChQ4n1qdiHw/ljzgf79pf3zQ8fOXLEqTkfzgyG66Dx+dlnw+djD4Nvftw3P+9b644ZlW8+P5Vp06Y59aBBg9J+DDl3uD+Tb/1EZjJc643XHK9hZki+/XyI1xwzKOLx8v5cu47P79uDS8LQNyAREQlCA5CIiAShAUhERILI2Azo+PHjiXlr314kvr4fZh7MUFjz8ZhBMfPhXirMkHw9CLydr4/Hx/lsX6bku3+qPiieA74HV155ZbuPKRcWMx72/TAT8eWe/MwUFBQ4NTMZ3/48rNm7xrXjfJkU+Z5PGVBm0jcgEREJQgOQiIgEoQFIRESCyNgMKCcnJzGv7Vv7zdc3k24Gw4yHfT++zIf5Ce/PHoZ4PO7UzHz4+779fjg/z3yA54eZU6r7FBcXt1tLWIWFhU49cuRIp+Z+QMxEeM3wmuf9mRvyGuX6g779e9gXxNfD5/etz+jrK5LMoG9AIiIShAYgEREJQgOQiIgEkbEZUNeuXRPrS3G+mRkLb/ftReLbv8fXU8B1pwYMGODUXJeLj898hfPjzJT4fOQ7H6x5PlL1ATE3uvzyy536TNaPk/OHmQevCfYFMbPhNcs+Hd7OPh3ePmzYsHaff+/evdYe3x5gvtzXtxadZAZ9AxIRkSA0AImISBAagEREJIiMzYBOnjyZNE99ii/j4PwxMx/2GBw+fNipmfkwMxkzZoxTl5SUODUznD179jj1Bx984NTsmWDmw/ltnhfuxcI+IR4/17bj75sl51Z8zZJZeE0wY2lsbHRqZiTMjHgNsvb1CfEzwUyotLTUqQ8ePOjUvOZ5fLymeQ3z/pKZ9A1IRESC0AAkIiJBaAASEZEgMjYDiqIoMQ+cqk/F97unY88CMx5mRlznbPjw4U7NtdNef/11p/ZlPMyIiD027IHgWnHMfDi/z54eztfz9838+8FIZonFYk7NDOb99993an6meE3yM8FeNV4fqa6h9n6/srLSqUeNGuXUXLvu0KFDTu3r9fN9xiQz6BuQiIgEoQFIRESC0AAkIiJBZEUGxMyG87/MOFj/pX6iUy6++GKn5rpWdXV1Tr19+3an5nw1az6/b796Zjic3/btdcLjZ6bE+frPkrH179/fex8Jh+8pr+m1a9c6tS9X5DXIa445aF5enlOn6i073ccff+zUvEaHDBnS7u08Xj5fU1NTu88vmUHfgEREJAgNQCIiEoQGIBERCSJjM6DW1tZENsEeAmYq3LuE92eGwnWpOH/89ttvO/W2bducmmvH8fnIl7FwPpt4fFzLjvsRMVPi/Llvf6NUj8m+D8lszGyYi5JvvUFfrsrPADMmXsPs02GvHJ9v8ODBTs1rlo/Ha1wyk74BiYhIEBqAREQkiLQHoI8++shuvvlmKygosF69etnYsWPt1VdfTdweRZEtXbrUSkpKrFevXjZr1izbsWPHOT1oERHJfmllQIcOHbIZM2bYlVdeaf/7v/9rgwYNsh07djh5wX333Wf333+/Pfroo1ZRUWFLliyxa665xt555x3velGnO378eCK78e0Hz4yD+9341jGrr693au5NwgyHe42ku/+87/i5dh3PG3suyJeZ8fhT9UlxbTHmaJLZuJ4hMxK+53x/+Znz9Z7xM8JrnBkTc09mQHw+ZpCDBg1q9/l8vX+SGdIagO69914rKyuzlStXJn5WUVGR+N9RFNny5cvthz/8oc2ZM8fMzH79619bLBazJ5980m666aZzdNgiIpLt0pqC+/3vf2+TJk2yG264wYqKimz8+PH2yCOPJG7ftWuXNTQ02KxZsxI/y8/Pt6lTp9q6detSPmZLS4vF43Hnn4iIdHxpDUA7d+60Bx980CorK+3ZZ5+1b3/72/bd737XHn30UTMza2hoMLPk6ZtYLJa4jWpqaiw/Pz/xr6ys7Exeh4iIZJm0puDa2tps0qRJdvfdd5uZ2fjx423r1q320EMP2fz588/oABYvXmyLFi1K1PF43MrKyiwejyfmldlDwPlmzi9zAOTtXIeKPQV8fGZK/JbGngXffjx8PM7Xc76bx+PbC4U9EHz9zJxyc3ONOMcu2WXixIlOzf2BuJ4hrzlf3xDxGuM1ypp4zfIztmfPHqfmNTxw4ECn5nqMkpnS+gZUUlKStHHUyJEjbffu3Wb2f/8hbWxsdO7T2NiY9B/ZU3Jzc61fv37OPxER6fjSGoBmzJiRcmXooUOHmtmf/yChuLjYamtrE7fH43HbsGGDVVVVnYPDFRGRjiKt79m33367TZ8+3e6++2678cYbbePGjfbwww/bww8/bGZ//pq9cOFC+8lPfmKVlZWJP8MuLS21a6+99nwcv4iIZKm0BqDJkyfbE088YYsXL7a77rrLKioqbPny5TZv3rzEfe644w47cuSI3XLLLdbU1GQzZ860Z555Jq0eILM//3XcqWzDl7lwbTTe7uvzSbUWWnuPxwyHPQfMgPjauXadr+fCt18QMyI+H2u+3lTz8+qjyG68Rqurq536rrvucmr2hjF3Ze1b682XKfGa5TVOhw4davf209tBUj0fMyozfy4l51/ai5F++ctfti9/+ct/8fYuXbrYXXfdlXSBi4iInE5rwYmISBAagEREJIiM3Q8oiqLEvG1zc7NzG+duR48e7dTvv/++U/PPwtlzwLyDGYwvk2EfDv+UnPPj7GHg4x87dqzd30933S5mPrw91Tpv3H9Fshv7gk5frcTMklYq8a0XyGuSuSavceLjMaPh4/MzsX//fqdmo/vUqVOdWnlPZtI3IBERCUIDkIiIBKEBSEREgsjYDOjkyZOJeWLf/ji7du1y6jfffLPd+3M+mHulMCNhTwHnp7nfkC9zYQ8EMynW/H0+P4+fmY5vL5dUt3NtLelYvvCFLzj1O++849S8RpnBMMPheoK+DIjXOK9Z5r7cL4jHl5+f79RcMkwyk74BiYhIEBqAREQkCA1AIiISRMZmQC0tLYmso6ioyLmN61y99NJLTs0MiH05/fv3b/e5mbGwR4HrXPH2o0ePOnVLS4tTHz58uN2a89vMaPLy8tp9fj4ff589Hqn6gJi7ScdSWVnp1FdffbVTr1692qnZ58NclNccrylmRvyMsOb+P1z/8JJLLnFq5qCsJTPpG5CIiAShAUhERILQACQiIkFkbAZ0/PjxRL8OMxvuDcIeAWYiW7dubfe52LPAurS01KmZQTU1NTk157PZ08CeCs6np9u3xOPl4/P3OZ8+YMAAo1Q/k46LW6xs2LDBqbds2eLUvOaYAbEXjjVzT2ZEfPySkpJ278/MiX1Gkpn0DUhERILQACQiIkFoABIRkSAyNgNqaWlJZBfsy+H8LzMNrkvFzIZ7hzDDYebEDIXH4+v74fEy4+H+QsywmPnw9bJHg/h4PJ7rrrsu6Xe4tpZ0bLwGb7zxRqd+8cUXnZrXFPEzwf17+Jni87PmZ5LPz8yHn0HJTPoGJCIiQWgAEhGRIDQAiYhIEBmbAR07diwxz+vbn4c9A+wJ4O1ca41rqzH/YM+Cr0+HGQ2PlzifHY/HnZo9FHx9zKT4fKynT5/u1DfccEPSMfE1Secyfvx4p66qqnLqF154wan5GeJnhJ/BvXv3OjWvYa5FyEyIOabvMyaZSd+AREQkCA1AIiIShAYgEREJImMnTk+ePJnIOjjfy/ngVPvZnI7zy74+IeYf7ClgxsNMifPXfDy+Hj4+MyA+H18v9/cZPHiwU1955ZVOff311zt1WVmZiZyO1yyvmaefftqp+ZniZ5QZET+TXN+Rv88cmLkpMyB+xiQz6RuQiIgEoQFIRESC0AAkIiJBaAASEZEgMvaPEFpbWxPhO0N43wZy/KMABp6DBg1q93b+EQADTy60+Fk2eDsdF07kYqNsPOUfGfCPEMaNG+fU1157rVN/4QtfcOpLLrnEqdV0Kj5sRJ00aZJTr1271qm5gRyvMf6hDq9p/lEB/wiBn1nfHyalWjxV1314+gYkIiJBaAASEZEgNACJiEgQGZsBtbW1JeZ9jx075tzGzam48CHnfznXW1hY6NR8fGYyzHy4OCmb8DhfzQzn4MGDTs3Mqbm52anZKMqMZ+7cuU59+eWXOzXPl0i6mMl86Utfcuo//vGPTs1rmJ85Zji8nZ9Z34LEvXv3dmo2d/Mza2bWr1+/pJ/JhaVvQCIiEoQGIBERCUIDkIiIBJGxGdDJkycT88TMaLhhnG8ulxkRexDYx8P7c/Mszi8zc2JmxOPft2+fU7OP6eabb3bqW2+91am5WRh7IETONy5wy74f5pzMIbkAMD+TzFWZkzID4meWi5FqcdLMpG9AIiIShAYgEREJQgOQiIgEkRUZEOdvudYb55eZyfj6hFjz8Zn5cP6aPQ3sOWA9ZcoUp168eLFTX3XVVU6tjEcyzZAhQ5x62rRpTv3UU085Ndc35HqJ/Ayyr4d8mzTydvbiSWbQNyAREQlCA5CIiAShAUhERILI2Azo9Dlb7p/D+dy8vDynZubDvUCY6RCfj+tQcb6Z617FYjGnvvvuu536xhtvdGoev0i2ueKKK5yaa8PxM8jPMHNU9sYxB+Xvc+045rjKgDKTvgGJiEgQGoBERCQIDUAiIhJExmZAR44cSfT/MJPh3/hzvphrxTHzYc2129h3xHWn2Nczbtw4p37wwQedesyYMSbSkVVWVjo1P4PMgLjnlu8zzrXimAnxM8tMiBmTZAa9KyIiEoQGIBERCUIDkIiIBJGxGdAnn3ySmOflfDHnezm/O2jQIKduampyavb1HDp0qN3HZw8B969/9NFHnfqiiy4ykc5k9OjRTj18+HCnfvvtt52a6ykyh/Wt9cbPvC8D4mdeMoO+AYmISBAagEREJAgNQCIiEkRGZ0Cn+m/Yd8OeAe4dUlBQ4NQNDQ3t1tyrhJkP15VatmyZUyvzkc6ub9++Tj1x4kSnfuutt5yaGQ577ZjZ+NZyy83NdWrf2nCSGfQNSEREgtAAJCIiQWgAEhGRIDI2AyovL0+s8XbgwAHnNmY2nH9mJsT954nzz/F43Km5f89XvvKVdh9PpLO77rrrnPrZZ591amY0XOuNfUHMhHyfca4Vpz6gzKRvQCIiEoQGIBERCUIDkIiIBJGxGVBlZaX17NnTzMw2btzo3Ma+oFgs5tRcZ+rU4/ylmvPPvH3u3Lmf8ahFxCx5D6xvfvObTv3kk086Ndd+Y98PP/NDhgxxan7mmQFpP6DMpHdFRESCSGsAam1ttSVLllhFRYX16tXLhg8fbj/+8Y+d3Q6jKLKlS5daSUmJ9erVy2bNmmU7duw45wcuIiLZLa0B6N5777UHH3zQ/u3f/s3effddu/fee+2+++6zBx54IHGf++67z+6//3576KGHbMOGDdanTx+75pprkpbPERGRzi2tDGjt2rU2Z84cmz17tpmZDRs2zH7zm98kMpooimz58uX2wx/+0ObMmWNmZr/+9a8tFovZk08+aTfddNNnfq4oihLfrLifD2vOH7MviPr16+fUzHymTp3q1LNmzfIdroi04/rrr3fqffv2OfWaNWucmnt0cT8gru12qmfwFOa6RUVFn/1g5YJJ6xvQ9OnTrba21rZv325mZlu2bLGXX37ZvvjFL5qZ2a5du6yhocH5D3Z+fr5NnTrV1q1bl/IxW1paLB6PO/9ERKTjS+sb0J133mnxeNxGjBhh3bp1s9bWVlu2bJnNmzfPzP5vlWn+VVosFktagfqUmpoa+9GPfnQmxy4iIlksrW9Av/3tb+2xxx6zVatW2WuvvWaPPvqo/cu//EvSltTpWLx4sTU3Nyf+1dfXn/FjiYhI9kjrG9D3vvc9u/POOxNZztixY+2DDz6wmpoamz9/vhUXF5uZWWNjo5WUlCR+r7Gx0caNG5fyMXNzc5P28jD78x7zp+Zxn376aee25uZmpz5y5IhTM+Ph/DHXkWJ9xRVXtPv7IpKevLw8p7766qudetu2bU7N/yPKXPfYsWNOzbXlSktL2/19yQxpfQM6evRoUkNXt27dEgv9VVRUWHFxsdXW1iZuj8fjtmHDBquqqjoHhysiIh1FWt+A/vqv/9qWLVtm5eXlNnr0aHv99dftZz/7mX396183sz//v5CFCxfaT37yE6usrLSKigpbsmSJlZaW2rXXXns+jl9ERLJUWgPQAw88YEuWLLHvfOc7tnfvXistLbV/+Id/sKVLlybuc8cdd9iRI0fslltusaamJps5c6Y988wzSX/qLCIinVtaA1BeXp4tX77cli9f/hfv06VLF7vrrrvsrrvuOqsDGzZsWGLemHt58E+1mQkNGjTIqU9fqeHUMZ6OPQPTpk1L/4BF5DO75JJLnHr06NFO/cEHHzg1P/P8TDOn5eNJZtJacCIiEoQGIBERCUIDkIiIBJGx+wGVlZUl+nkmTJjg3MbVtVtaWpyamRAzH9/acfn5+ekfsIh8Zr71F+vq6pz63XffdWp+5vl4WvstO+gbkIiIBKEBSEREgtAAJCIiQWRsBpSTk2M5OX8+PK6i8M///M9OffToUafm5nfMgE6ePOnU7CEYMGBAuocrImdhxIgRTl1ZWenUH330kVOf+m/DKTNnznRqfuYlM+kbkIiIBKEBSEREgtAAJCIiQWRsBnQ6buUwY8YMp967d69TFxYWOjX3i+/evbtTs6eAe5eIyPk1cOBAp2bvH9eG+8pXvuLUY8aMcWrf+o+SGfQNSEREgtAAJCIiQWgAEhGRILIiA2Jmc8sttzj1f//3fzs1+4D4+8yIDh065NTcdlxELqyxY8c69aWXXurUpaWl7f6+Mp/soP/SiohIEBqAREQkCA1AIiISRFZkQFRWVubUt912m1OzL2j9+vVOzbXgjh07dg6PTkTOVkNDg1Pn5uY6tfp8OgZ9AxIRkSA0AImISBAagEREJIiszICIfTvFxcVOPWfOHKfes2ePUx88eNCp2TckIucXMx3uD8TePukY9A1IRESC0AAkIiJBaAASEZEgOkQG5MMeAa4j5VtXSkTOL35Gc3Lc/zT17dv3Qh6OXCD6BiQiIkFoABIRkSA0AImISBAagEREJAgNQCIiEoQGIBERCUIDkIiIBKEBSEREgtAAJCIiQWgAEhGRIDJuKZ5Ty7LH4/HARyIiImfi1H+/uc0GZdwAdPjwYTMzKysrC3wkIiJyNg4fPmz5+fl/8fYukW+IusDa2trs448/tiiKrLy83Orr661fv36hDysrxeNxKysr0zk8Qzp/Z0fn7+xl6zmMosgOHz5spaWlSRuGni7jvgF17drVhgwZkvgK169fv6w68ZlI5/Ds6PydHZ2/s5eN57C9bz6n6I8QREQkCA1AIiISRMYOQLm5ufZP//RPlpubG/pQspbO4dnR+Ts7On9nr6Ofw4z7IwQREekcMvYbkIiIdGwagEREJAgNQCIiEoQGIBERCUIDkIiIBJGxA9CKFSts2LBh1rNnT5s6dapt3Lgx9CFlpJqaGps8ebLl5eVZUVGRXXvttVZXV+fc5/jx41ZdXW0FBQXWt29fmzt3rjU2NgY64sx2zz33WJcuXWzhwoWJn+n8+X300Ud28803W0FBgfXq1cvGjh1rr776auL2KIps6dKlVlJSYr169bJZs2bZjh07Ah5x5mhtbbUlS5ZYRUWF9erVy4YPH24//vGPnYU8O+z5izLQ448/HvXo0SP6j//4j+jtt9+OvvnNb0b9+/ePGhsbQx9axrnmmmuilStXRlu3bo3eeOON6Etf+lJUXl4effLJJ4n7fOtb34rKysqi2tra6NVXX42mTZsWTZ8+PeBRZ6aNGzdGw4YNiy677LLotttuS/xc5699Bw8ejIYOHRp99atfjTZs2BDt3LkzevbZZ6P33nsvcZ977rknys/Pj5588sloy5Yt0d/8zd9EFRUV0bFjxwIeeWZYtmxZVFBQED399NPRrl27otWrV0d9+/aN/vVf/zVxn456/jJyAJoyZUpUXV2dqFtbW6PS0tKopqYm4FFlh71790ZmFq1ZsyaKoihqamqKunfvHq1evTpxn3fffTcys2jdunWhDjPjHD58OKqsrIyee+656K/+6q8SA5DOn9/3v//9aObMmX/x9ra2tqi4uDj66U9/mvhZU1NTlJubG/3mN7+5EIeY0WbPnh19/etfd352/fXXR/PmzYuiqGOfv4ybgjtx4oRt3rzZZs2alfhZ165dbdasWbZu3bqAR5Ydmpubzcxs4MCBZma2efNmO3nypHM+R4wYYeXl5Tqfp6murrbZs2c758lM5++z+P3vf2+TJk2yG264wYqKimz8+PH2yCOPJG7ftWuXNTQ0OOcwPz/fpk6dqnNoZtOnT7fa2lrbvn27mZlt2bLFXn75ZfviF79oZh37/GXcatj79++31tZWi8Vizs9jsZht27Yt0FFlh7a2Nlu4cKHNmDHDxowZY2ZmDQ0N1qNHD+vfv79z31gsZg0NDQGOMvM8/vjj9tprr9mmTZuSbtP589u5c6c9+OCDtmjRIvvBD35gmzZtsu9+97vWo0cPmz9/fuI8pfpM6xya3XnnnRaPx23EiBHWrVs3a21ttWXLltm8efPMzDr0+cu4AUjOXHV1tW3dutVefvnl0IeSNerr6+22226z5557znr27Bn6cLJSW1ubTZo0ye6++24zMxs/frxt3brVHnroIZs/f37go8t8v/3tb+2xxx6zVatW2ejRo+2NN96whQsXWmlpaYc/fxk3BVdYWGjdunVL+iujxsZGKy4uDnRUmW/BggX29NNP2wsvvGBDhgxJ/Ly4uNhOnDhhTU1Nzv11Pv9s8+bNtnfvXpswYYLl5ORYTk6OrVmzxu6//37LycmxWCym8+dRUlJio0aNcn42cuRI2717t5lZ4jzpM53a9773PbvzzjvtpptusrFjx9rf/d3f2e233241NTVm1rHPX8YNQD169LCJEydabW1t4mdtbW1WW1trVVVVAY8sM0VRZAsWLLAnnnjCnn/+eauoqHBunzhxonXv3t05n3V1dbZ7926dTzO76qqr7K233rI33ngj8W/SpEk2b968xP/W+WvfjBkzkv70f/v27TZ06FAzM6uoqLDi4mLnHMbjcduwYYPOoZkdPXo0adfQbt26WVtbm5l18PMX+q8gUnn88cej3Nzc6Fe/+lX0zjvvRLfcckvUv3//qKGhIfShZZxvf/vbUX5+fvTiiy9Ge/bsSfw7evRo4j7f+ta3ovLy8uj555+PXn311aiqqiqqqqoKeNSZ7fS/gosinT+fjRs3Rjk5OdGyZcuiHTt2RI899ljUu3fv6D//8z8T97nnnnui/v37R0899VT05ptvRnPmzOkQf0Z8LsyfPz8aPHhw4s+wf/e730WFhYXRHXfckbhPRz1/GTkARVEUPfDAA1F5eXnUo0ePaMqUKdH69etDH1JGMrOU/1auXJm4z7Fjx6LvfOc70YABA6LevXtH1113XbRnz55wB53hOADp/Pn9z//8TzRmzJgoNzc3GjFiRPTwww87t7e1tUVLliyJYrFYlJubG1111VVRXV1doKPNLPF4PLrtttui8vLyqGfPntFFF10U/eM//mPU0tKSuE9HPX/aD0hERILIuAxIREQ6Bw1AIiIShAYgEREJQgOQiIgEoQFIRESC0AAkIiJBaAASEZEgNACJiEgQGoBERCQIDUAiIhKEBiAREQni/wEujvoITyFL0wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_batched['image'][0]\n",
        "imagen = sample_batched['image'][0]\n",
        "imagen = np.squeeze(imagen)\n",
        "# Muestra la imagen en escala de grises\n",
        "plt.imshow(imagen,cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLJ79lVaZ3dB"
      },
      "source": [
        "**DistributedTraining.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "llQFTX8HZ5Ht"
      },
      "outputs": [],
      "source": [
        "def loss_batch(loss_func, xb, yb, yb_h, opt=None):\n",
        "    # Obtain the loss\n",
        "    size_yh = yb_h.size()\n",
        "    size_y = yb.size()\n",
        "    # print(size_yh)\n",
        "    # print(size_y)\n",
        "    loss = loss_func(yb_h, yb)\n",
        "    # Obtain peformance metric\n",
        "    metric_b = metrics_batch(yb, yb_h)\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), metric_b\n",
        "    # return metric_b\n",
        "\n",
        "# Helper function to compute the accuracy per mini_batch\n",
        "\n",
        "\n",
        "def metrics_batch(target, output):\n",
        "    # Obtain output class\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    # Compare output class with target class\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    return corrects\n",
        "\n",
        "# Helper function to compute the loss and metric values for a dataset\n",
        "\n",
        "\n",
        "def loss_epoch(device, model, loss_func, dataset_dl, opt=None):\n",
        "    loss = 0.0\n",
        "    metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "    for i, data in enumerate(dataset_dl, 0):\n",
        "        # print('batch: ', i)\n",
        "        xb, yb = data['image'], data['label']\n",
        "        xb = xb.type(torch.double).to(device, dtype=torch.float32)\n",
        "        yb = yb.to(device, dtype=torch.long)\n",
        "\n",
        "        # Obtain model output\n",
        "        yb_h = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, xb, yb, yb_h, opt)\n",
        "        loss += loss_b\n",
        "        if metric_b is not None:\n",
        "            metric += metric_b\n",
        "\n",
        "    loss /= len_data\n",
        "    metric /= len_data\n",
        "\n",
        "    return loss, metric\n",
        "    # return metric\n",
        "\n",
        "# Define the training function\n",
        "\n",
        "\n",
        "def train_val(device, epochs, model, opt, loss_func, train_dl, test_dl):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # print(epoch)\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(\n",
        "            device, model, loss_func, train_dl, opt)\n",
        "        # train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(\n",
        "                device, model, loss_func, test_dl)\n",
        "            # val_metric = loss_epoch(model, loss_func, test_dl)\n",
        "        accuracy = val_metric\n",
        "\n",
        "        # print(\"Epoch: %d, train loss: %.6f, val loss: %.6f, test accuracy: %.2f\" %(epoch, train_loss, val_loss, accuracy))\n",
        "\n",
        "    return accuracy, model\n",
        "\n",
        "\n",
        "def training(num, device, model, n_epochs, loss_func, train_dl, test_dl, lr, w, max_params):\n",
        "    # Number of parameters\n",
        "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Obtaining training accuracy\n",
        "    accuracy, _ = train_val(device, n_epochs, model, opt,\n",
        "                            loss_func, train_dl, test_dl)\n",
        "\n",
        "    # Fitness function based on accuracy and No. of parameters\n",
        "    # f = abs(accuracy - w*(1 - abs((max_params - params)/max_params)))\n",
        "    f = (1 - w)*accuracy + w*((max_params - params)/max_params)\n",
        "    '''if params < max_params:\n",
        "        f = (1 - w)*accuracy + abs(w*((max_params - params)/max_params))'''\n",
        "    '''else:\n",
        "        #f = (1 - w)*accuracy - abs(w*((max_params - params)/max_params))\n",
        "        f = accuracy - abs((max_params - params)/max_params)'''\n",
        "\n",
        "    # Append results to multiprocessing list\n",
        "    # acc_list.append([num, f, accuracy, params])\n",
        "    return num, f, accuracy, params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieZzagSsYOaj"
      },
      "source": [
        "**Loading GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEdRSBJoYQbx",
        "outputId": "657bceed-5124-4d4a-f88e-17e6670b09cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.cudaStatus.ERROR_NOT_READY)\n",
        "if torch.cuda.is_available():\n",
        "  device1 = torch.device(\"cuda:0\")\n",
        "  # device1 = torch.device(\"cpu\")\n",
        "  print(device1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dXCfouwaYbN"
      },
      "source": [
        "**DeepGA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "HCsj6taeabkX"
      },
      "outputs": [],
      "source": [
        "#Maximun and minimum numbers of layers to initialize networks\n",
        "min_conv = 2\n",
        "max_conv = 6\n",
        "min_full = 1\n",
        "max_full = 6\n",
        "\n",
        "'''Genetic Algorithm Parameters'''\n",
        "cr = 0.7 #Crossover rate\n",
        "mr = 0.5 #Mutation rate\n",
        "N = 20 #Population size\n",
        "T = 50 #Number of generations\n",
        "t_size = 6 #tournament size\n",
        "w = 0.3 #penalization weight\n",
        "max_params = 3e6\n",
        "num_epochs = 5 # TODO: retrunt to 50\n",
        "lr = 1e-3\n",
        "# loss_func = nn.NLLLoss(reduction = \"sum\")\n",
        "# loss_func = nn.NLLLoss()\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPU_DA7sbHbe",
        "outputId": "9ef287c9-cf7c-4c56-8d42-b65eb492fc58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialize population\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(16, 4, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
            "    (7): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
            "    (11): Conv2d(20, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(40, 4, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=144, out_features=64, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=128, out_features=8, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=8, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (4): Conv2d(16, 2, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(50, 4, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1764, out_features=8, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=8, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            "    (7): Conv2d(40, 16, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(24, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(40, 4, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1156, out_features=64, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=64, out_features=4, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=4, out_features=4, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4, out_features=16, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=16, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(16, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(24, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            "    (11): Conv2d(26, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(10, 8, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=3528, out_features=8, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=8, out_features=32, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (4): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=7744, out_features=4, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=4, out_features=32, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=32, out_features=128, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=64, out_features=4, bias=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Linear(in_features=4, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (8): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=3200, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(16, 2, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(2, 32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): AvgPool2d(kernel_size=5, stride=2, padding=0)\n",
            "    (11): Conv2d(48, 32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            "    (18): Conv2d(18, 2, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=8, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=8, out_features=128, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=128, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 2, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(6, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): AvgPool2d(kernel_size=5, stride=2, padding=0)\n",
            "    (11): Conv2d(14, 2, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(2, 8, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(24, 16, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=4, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=4, out_features=128, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=128, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
            "    (4): Conv2d(32, 4, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1600, out_features=8, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=8, out_features=64, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=16, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): AvgPool2d(kernel_size=5, stride=2, padding=0)\n",
            "    (7): Conv2d(32, 16, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=6400, out_features=32, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=32, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AvgPool2d(kernel_size=5, stride=2, padding=0)\n",
            "    (4): Conv2d(32, 2, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=4050, out_features=32, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=32, out_features=8, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=8, out_features=32, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=32, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(4, 2, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1058, out_features=32, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=16, out_features=128, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=128, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AvgPool2d(kernel_size=5, stride=2, padding=0)\n",
            "    (4): Conv2d(32, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(40, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(64, 4, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(36, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=4, out_features=128, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=128, out_features=4, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=4, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(8, 4, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(4, 4, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(12, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=8192, out_features=16, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=16, out_features=128, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=128, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=264992, out_features=32, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(32, 16, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25600, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=4, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=4, out_features=4, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4, out_features=8, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=8, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            "    (4): Conv2d(4, 32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=14112, out_features=64, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Linear(in_features=128, out_features=8, bias=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Linear(in_features=8, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): AvgPool2d(kernel_size=5, stride=2, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=12800, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=32, out_features=8, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=8, out_features=4, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=4, out_features=8, bias=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Linear(in_features=8, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 2, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
            "    (8): Conv2d(4, 16, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (12): Conv2d(18, 8, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "CNN(\n",
            "  (extraction): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(4, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=6400, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=8, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=8, out_features=64, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Linear(in_features=32, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "Generation:  0\n",
            "Best fitness:  0.812289133711048\n",
            "Best accuracy:  0.7337110481586402\n",
            "Best No. of Params:  13086\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  1\n",
            "Best fitness:  0.812289133711048\n",
            "Best accuracy:  0.7337110481586402\n",
            "Best No. of Params:  13086\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  2\n",
            "Best fitness:  0.812289133711048\n",
            "Best accuracy:  0.7337110481586402\n",
            "Best No. of Params:  13086\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  3\n",
            "Best fitness:  0.812289133711048\n",
            "Best accuracy:  0.7337110481586402\n",
            "Best No. of Params:  13086\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  4\n",
            "Best fitness:  0.812289133711048\n",
            "Best accuracy:  0.7337110481586402\n",
            "Best No. of Params:  13086\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  5\n",
            "Best fitness:  0.812289133711048\n",
            "Best accuracy:  0.7337110481586402\n",
            "Best No. of Params:  13086\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  6\n",
            "Best fitness:  0.8203653478753541\n",
            "Best accuracy:  0.7478753541076487\n",
            "Best No. of Params:  31474\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  7\n",
            "Best fitness:  0.8223189507082154\n",
            "Best accuracy:  0.7507082152974505\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  8\n",
            "Best fitness:  0.8223189507082154\n",
            "Best accuracy:  0.7507082152974505\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  9\n",
            "Best fitness:  0.8223189507082154\n",
            "Best accuracy:  0.7507082152974505\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  10\n",
            "Best fitness:  0.8223189507082154\n",
            "Best accuracy:  0.7507082152974505\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  11\n",
            "Best fitness:  0.8223189507082154\n",
            "Best accuracy:  0.7507082152974505\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  12\n",
            "Best fitness:  0.8223189507082154\n",
            "Best accuracy:  0.7507082152974505\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  13\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  14\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  15\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  16\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  17\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  18\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  19\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  20\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  21\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  22\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  23\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  24\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  25\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  26\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  27\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  28\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  29\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  30\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  31\n",
            "Best fitness:  0.8322339648725212\n",
            "Best accuracy:  0.7648725212464589\n",
            "Best No. of Params:  31768\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  32\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  33\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  34\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  35\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  36\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  37\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  38\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  39\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  40\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  41\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  42\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  43\n",
            "Best fitness:  0.8323681790368271\n",
            "Best accuracy:  0.7790368271954674\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  44\n",
            "Best fitness:  0.8363341847025494\n",
            "Best accuracy:  0.7847025495750708\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  45\n",
            "Best fitness:  0.8363341847025494\n",
            "Best accuracy:  0.7847025495750708\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  46\n",
            "Best fitness:  0.8363341847025494\n",
            "Best accuracy:  0.7847025495750708\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  47\n",
            "Best fitness:  0.8363341847025494\n",
            "Best accuracy:  0.7847025495750708\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  48\n",
            "Best fitness:  0.8363341847025494\n",
            "Best accuracy:  0.7847025495750708\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Generation:  49\n",
            "Best fitness:  0.8363341847025494\n",
            "Best accuracy:  0.7847025495750708\n",
            "Best No. of Params:  129576\n",
            "No. of Conv. Layers:  4\n",
            "No. of FC Layers:  1\n",
            "--------------------------------------------\n",
            "Execution time:  0.08005370286138916\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from multiprocessing import Process, Manager\n",
        "from torchsummary import summary\n",
        "\n",
        "'''Initialize population'''\n",
        "print('Initialize population')\n",
        "\n",
        "# train_dl, test_dl = loading_data()\n",
        "\n",
        "start = timeit.default_timer()\n",
        "pop = []\n",
        "bestAcc = []\n",
        "bestF = []\n",
        "bestParams = []\n",
        "# manager = Manager()\n",
        "while len(pop) < N:\n",
        "    # acc_list = manager.list()\n",
        "\n",
        "    # Creating genomes (genetic encoding)\n",
        "    e1 = Encoding(min_conv, max_conv, min_full, max_full)\n",
        "    # e2 = Encoding(min_conv,max_conv,min_full,max_full)\n",
        "\n",
        "    # Decoding the networks\n",
        "    network1 = decoding(e1)\n",
        "    # network2 = decoding(e2)\n",
        "    # print(network1)\n",
        "\n",
        "    # Creating the CNNs\n",
        "    # print(network1[2])\n",
        "    cnn1 = CNN(e1, network1[0], network1[1], network1[2])\n",
        "    print(cnn1)\n",
        "    # cnn2 = CNN(e2, network2[0], network2[1], network2[2])\n",
        "    # Evaluate individuals\n",
        "    num1, f1, accuracy1, params1 = training('1', device1, cnn1, num_epochs, loss_func,\n",
        "                                            train_dl, test_dl, lr, w, max_params)\n",
        "\n",
        "    # training2 = Process(target = training, args = ('2', device2, cnn2, num_epochs, loss_func,\n",
        "    #                                              train_dl, test_dl, lr, w, max_params, acc_list))\n",
        "\n",
        "    # training1.start()\n",
        "    # training2.start()\n",
        "    # training1.join()\n",
        "    # training2.join()\n",
        "\n",
        "    # if acc_list[0][0] == '1':\n",
        "    pop.append([e1, f1, accuracy1, params1])\n",
        "    # pop.append([e2, acc_list[1][1], acc_list[1][2], acc_list[1][3]])\n",
        "    # else:\n",
        "    # pop.append([e2, acc_list[0][1], acc_list[0][2], acc_list[0][3]])\n",
        "    # pop.append([e1, acc_list[1][1], acc_list[1][2], acc_list[1][3]])\n",
        "\n",
        "'''Genetic Algorithm'''\n",
        "for t in range(T):\n",
        "    print('Generation: ', t)\n",
        "\n",
        "    # Parents Selection\n",
        "    parents = []\n",
        "    while len(parents) < int(N/2):\n",
        "        # Tournament Selection\n",
        "        tournament = random.sample(pop, t_size)\n",
        "        p1 = selection(tournament, 'max')\n",
        "        tournament = random.sample(pop, t_size)\n",
        "        p2 = selection(tournament, 'max')\n",
        "        while p1 == p2:\n",
        "            tournament = random.sample(pop, t_size)\n",
        "            p2 = selection(tournament, 'max')\n",
        "\n",
        "        parents.append(p1)\n",
        "        parents.append(p2)\n",
        "\n",
        "    # Reproduction\n",
        "    offspring = []\n",
        "    while len(offspring) < int(N/2):\n",
        "        par = random.sample(parents, 2)\n",
        "        # Crossover + Mutation\n",
        "        if cr >= random.uniform(0, 1):  # Crossover\n",
        "            p1 = par[0][0]\n",
        "            p2 = par[1][0]\n",
        "            c1, c2 = crossover(p1, p2)\n",
        "\n",
        "            # Mutation\n",
        "            if mr >= random.uniform(0, 1):\n",
        "                mutation(c1)\n",
        "\n",
        "            if mr >= random.uniform(0, 1):\n",
        "                mutation(c2)\n",
        "\n",
        "            # Evaluate offspring\n",
        "            # acc_list = manager.list()\n",
        "\n",
        "            # Decoding the network\n",
        "            network1 = decoding(c1)\n",
        "            network2 = decoding(c2)\n",
        "\n",
        "            # Creating the CNN\n",
        "            cnn1 = CNN(c1, network1[0], network1[1], network1[2])\n",
        "            cnn2 = CNN(c2, network2[0], network2[1], network2[2])\n",
        "\n",
        "            # Evaluate individuals\n",
        "            num_cnn1, f_cnn1, accuracy_cnn1, params_cnn1 = training('1', device1, cnn1, num_epochs, loss_func,\n",
        "                                                                    train_dl, test_dl, lr, w, max_params)\n",
        "            offspring.append([c1, f_cnn1, accuracy_cnn1, params_cnn1])\n",
        "\n",
        "            num_cnn2, f_cnn2, accuracy_cnn2, params_cnn2 = training('2', device1, cnn2, num_epochs, loss_func,\n",
        "                                                                    train_dl, test_dl, lr, w, max_params)\n",
        "            offspring.append([c2, f_cnn2, accuracy_cnn2, params_cnn2])\n",
        "\n",
        "    # Replacement with elitism\n",
        "    pop = pop + offspring\n",
        "    pop.sort(reverse=True, key=lambda x: x[1])\n",
        "    pop = pop[:N]\n",
        "\n",
        "    leader = max(pop, key=lambda x: x[1])\n",
        "    bestAcc.append(leader[2])\n",
        "    bestF.append(leader[1])\n",
        "    bestParams.append(leader[3])\n",
        "\n",
        "    print('Best fitness: ', leader[1])\n",
        "    print('Best accuracy: ', leader[2])\n",
        "    print('Best No. of Params: ', leader[3])\n",
        "    print('No. of Conv. Layers: ', leader[0].n_conv)\n",
        "    print('No. of FC Layers: ', leader[0].n_full)\n",
        "    print('--------------------------------------------')\n",
        "\n",
        "results = pd.DataFrame(list(zip(bestAcc, bestF, bestParams)), columns=[\n",
        "                       'Accuracy', 'Fitness', 'No. Params'])\n",
        "final_networks = []\n",
        "final_connections = []\n",
        "objects = []\n",
        "for member in pop:\n",
        "    p = member[0]\n",
        "    objects.append(p)\n",
        "    n_conv = p.n_conv\n",
        "    n_full = p.n_full\n",
        "    description = 'The network has ' + \\\n",
        "        str(n_conv) + ' convolutional layers ' + 'with: '\n",
        "    for i in range(n_conv):\n",
        "        nfilters = str(p.first_level[i]['nfilters'])\n",
        "        fsize = str(p.first_level[i]['fsize'])\n",
        "        pool = str(p.first_level[i]['pool'])\n",
        "        psize = str(p.first_level[i]['psize'])\n",
        "        layer = '(' + nfilters + ', ' + fsize + \\\n",
        "            ', ' + pool + ', ' + psize + ') '\n",
        "        description += layer\n",
        "    description += 'and '\n",
        "    description += str(n_full)\n",
        "    description += ' '\n",
        "    description += 'fully-connected layers with: '\n",
        "    for i in range(n_conv, n_conv+n_full):\n",
        "        neurons = str(p.first_level[i]['neurons'])\n",
        "        layer = '(' + neurons + ')'\n",
        "        description += layer\n",
        "    description += ' neurons'\n",
        "    final_networks.append(description)\n",
        "\n",
        "    connections = ''\n",
        "    for bit in p.second_level:\n",
        "        if bit == 1:\n",
        "            connections += 'one - '\n",
        "        if bit == 0:\n",
        "            connections += 'zero - '\n",
        "    final_connections.append(connections)\n",
        "\n",
        "\n",
        "final_population = pd.DataFrame(list(zip(final_networks, final_connections)), columns=[\n",
        "                                'Network Architecture', 'Connections'])\n",
        "\n",
        "'''Saving Results as CSV'''\n",
        "final_population.to_csv('final_population.csv', index=False)\n",
        "results.to_csv('results.csv', index=False)\n",
        "stop = timeit.default_timer()\n",
        "execution_time = (stop-start)/3600\n",
        "print(\"Execution time: \", execution_time)\n",
        "\n",
        "# Saving objects\n",
        "\n",
        "with open('cnns.pkl', 'wb') as output:\n",
        "    pickle.dump(objects, output, pickle.HIGHEST_PROTOCOL)\n",
        "    output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "ep7abBCVWhe-"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "I/O operation on closed file.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[106], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m final_connections \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m objects \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m      5\u001b[0m     p \u001b[38;5;241m=\u001b[39m member\n\u001b[1;32m      6\u001b[0m     objects\u001b[38;5;241m.\u001b[39mappend(p)\n",
            "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
          ]
        }
      ],
      "source": [
        "\n",
        "final_networks = []\n",
        "final_connections = []\n",
        "objects = []\n",
        "for member in output:\n",
        "    p = member\n",
        "    objects.append(p)\n",
        "    n_conv = p.n_conv\n",
        "    n_full = p.n_full\n",
        "    description = 'The network has ' + str(n_conv) + ' convolutional layers ' + 'with: '\n",
        "    for i in range(n_conv):\n",
        "        nfilters = str(p.first_level[i]['nfilters'])\n",
        "        fsize = str(p.first_level[i]['fsize'])\n",
        "        pool = str(p.first_level[i]['pool'])\n",
        "        psize = str(p.first_level[i]['psize'])\n",
        "        layer = '(' + nfilters + ', ' + fsize + ', ' + pool + ', ' + psize + ') '\n",
        "        description += layer\n",
        "    description += 'and '\n",
        "    description += str(n_full)\n",
        "    description += ' '\n",
        "    description += 'fully-connected layers with: '\n",
        "    for i in range(n_conv, n_conv+n_full):\n",
        "        neurons = str(p.first_level[i]['neurons'])\n",
        "        layer = '(' + neurons + ')'\n",
        "        description += layer\n",
        "    description += ' neurons'\n",
        "    final_networks.append(description)\n",
        "\n",
        "    connections = ''\n",
        "    for bit in p.second_level:\n",
        "        if bit == 1:\n",
        "            connections += 'one - '\n",
        "        if bit == 0:\n",
        "            connections += 'zero - '\n",
        "    final_connections.append(connections)\n",
        "\n",
        "\n",
        "#final_population = pd.DataFrame(list(zip(final_networks, final_connections)), columns = ['Network Architecture', 'Connections'])\n",
        "\n",
        "'''Saving Results as CSV'''\n",
        "#final_population.to_csv('final_population.csv', index = False)\n",
        "#results.to_csv('results.csv', index = False)\n",
        "#stop = timeit.default_timer()\n",
        "#execution_time = (stop-start)/3600\n",
        "#print(\"Execution time: \", execution_time)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
