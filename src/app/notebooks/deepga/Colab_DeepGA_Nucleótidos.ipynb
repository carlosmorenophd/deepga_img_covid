{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFBKpZCoYD8n"
      },
      "source": [
        "**Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "zqdHL7Z_X84C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10860.68s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "LWqw4OXWYCay"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10866.89s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-forecasting in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.14.0)\n",
            "Requirement already satisfied: pytorch-optimizer<3.0.0,>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (3.9.1)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.5.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (0.14.2)\n",
            "Requirement already satisfied: fastapi>=0.80 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (0.111.1)\n",
            "Requirement already satisfied: optuna<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (3.6.1)\n",
            "Requirement already satisfied: pandas<=3.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.2.2)\n",
            "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.3.3)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (2.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (2.8.2)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.0.9)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.37.2)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (3.1.4)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.30.3)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (0.27.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (4.12.2)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.80->pytorch-forecasting) (2.2.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.1)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.0.post0)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.66.4)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.0.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.3.3)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.1)\n",
            "Requirement already satisfied: fsspec[http]<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2024.6.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.11.6)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (2.0.31)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (1.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (11.0.2.54)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.15.4)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.0.0->pytorch-forecasting) (12.5.82)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (4.53.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (3.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (0.12.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (10.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pytorch-forecasting) (1.4.5)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pytorch-forecasting) (0.5.6)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting) (1.3.5)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi>=0.80->pytorch-forecasting) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi>=0.80->pytorch-forecasting) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (0.12.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.9.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (1.0.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (4.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (2024.7.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.80->pytorch-forecasting) (2.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (59.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pytorch-forecasting) (1.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.80->pytorch-forecasting) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.80->pytorch-forecasting) (2.20.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting) (3.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (8.1.7)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (1.0.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (0.6.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (0.22.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi>=0.80->pytorch-forecasting) (12.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (23.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.5)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.9.4)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi>=0.80->pytorch-forecasting) (1.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.80->pytorch-forecasting) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10873.29s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-forecasting\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJlStn3nKmEe",
        "outputId": "943291d6-9413-4762-d616-233796284312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10879.46s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tjH01sKKsJu",
        "outputId": "73f6a6f6-f32c-4f8f-ad82-e2ddb9fe9c19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10885.63s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlwt in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->torchvision) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install xlwt torchsummary torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWXiuMYzYJIk"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "laZjSYBuYLER"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "import scipy.io\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz3PivL1ZjNq"
      },
      "source": [
        "**Operators.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "7KRbWus4ZldZ"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def crossover(x, y):\n",
        "    x = deepcopy(x)\n",
        "    y = deepcopy(y)\n",
        "\n",
        "    '''First parent'''\n",
        "    x_nconv = x.n_conv\n",
        "    x_nfull = x.n_full\n",
        "    xblocks = x.first_level\n",
        "    xbinary = x.second_level\n",
        "\n",
        "    '''Second parent'''\n",
        "    y_nconv = y.n_conv\n",
        "    y_nfull = y.n_full\n",
        "    yblocks = y.first_level\n",
        "    ybinary = y.second_level\n",
        "\n",
        "    '''Convolutional part crossover'''\n",
        "    if x_nconv > y_nconv:\n",
        "        k = math.floor(y_nconv/2)\n",
        "        index = list(range(x_nconv))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(k, y_nconv):\n",
        "            block = yblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            yblocks[i] = xblocks[ix]\n",
        "            xblocks[ix] = block\n",
        "\n",
        "    if y_nconv > x_nconv:\n",
        "        k = math.floor(x_nconv/2)\n",
        "        index = list(range(y_nconv))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(k, x_nconv):\n",
        "            block = xblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            xblocks[i] = yblocks[ix]\n",
        "            yblocks[ix] = block\n",
        "\n",
        "    if x_nconv == y_nconv:\n",
        "        k = math.floor(x_nconv/2)\n",
        "        index = list(range(x_nconv))\n",
        "\n",
        "        x_part = xblocks[k:x_nconv]\n",
        "\n",
        "        '''Exchaning last half of the blocks'''\n",
        "        xblocks[k:x_nconv] = yblocks[k:y_nconv]\n",
        "        yblocks[k:y_nconv] = x_part\n",
        "\n",
        "    '''Fully-connected part'''\n",
        "    if x_nfull > y_nfull:\n",
        "        k = math.floor(y_nfull/2)\n",
        "        index = list(range(x_nconv, x_nconv + x_nfull))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(y_nconv + k, y_nconv + y_nfull):\n",
        "            block = yblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            yblocks[i] = xblocks[ix]\n",
        "            xblocks[ix] = block\n",
        "\n",
        "    if y_nfull > x_nfull:\n",
        "        k = math.floor(x_nfull/2)\n",
        "        index = list(range(y_nconv, y_nconv + y_nfull))\n",
        "\n",
        "        '''Exchanging the last k blocks of the smaller parent'''\n",
        "        for i in range(x_nconv + k, x_nconv + x_nfull):\n",
        "            block = xblocks[i] #ith block\n",
        "            ix = random.choice(index) #Selecting random index from larger parent\n",
        "            index.remove(ix)\n",
        "\n",
        "            #Exchange of blocks\n",
        "            xblocks[i] = yblocks[ix]\n",
        "            yblocks[ix] = block\n",
        "\n",
        "    if x_nfull == y_nfull:\n",
        "        k = math.floor(x_nfull/2)\n",
        "\n",
        "        x_part = xblocks[x_nconv + k:x_nconv + x_nfull]\n",
        "        '''Exchaning last half of the blocks'''\n",
        "        xblocks[x_nconv + k:x_nconv + x_nfull] = yblocks[y_nconv + k:y_nconv + y_nfull]\n",
        "        yblocks[y_nconv + k:y_nconv + y_nfull] = x_part\n",
        "\n",
        "    '''Second level'''\n",
        "    if len(xbinary) > len(ybinary):\n",
        "        if len(ybinary) > 1 :\n",
        "            k = random.choice(list(range(1, len(ybinary))))\n",
        "            partition = ybinary[k:]\n",
        "            nbits = len(partition)\n",
        "\n",
        "            if random.uniform(0,1) >= 0.5:\n",
        "                ybinary[k:] = xbinary[len(xbinary) - nbits:len(xbinary)]\n",
        "                xbinary[len(xbinary) - nbits:len(xbinary)] = partition\n",
        "            else:\n",
        "                ybinary[k:] = xbinary[:nbits]\n",
        "                xbinary[:nbits] = partition\n",
        "\n",
        "    if len(ybinary) > len(xbinary):\n",
        "        if len(xbinary) > 1 :\n",
        "            k = random.choice(list(range(len(xbinary))))\n",
        "            partition = xbinary[k:]\n",
        "            nbits = len(partition)\n",
        "\n",
        "            if random.uniform(0,1) >= 0.5:\n",
        "                xbinary[k:] = ybinary[len(ybinary) - nbits:len(ybinary)]\n",
        "                ybinary[len(ybinary) - nbits:len(ybinary)] = partition\n",
        "            else:\n",
        "                xbinary[k:] = ybinary[:nbits]\n",
        "                ybinary[:nbits] = partition\n",
        "\n",
        "    if len(xbinary) == len(ybinary):\n",
        "        if len(xbinary) > 1 :\n",
        "            k = random.choice(list(range(len(xbinary))))\n",
        "            partition = xbinary[k:]\n",
        "\n",
        "            xbinary[k:] = ybinary[k:]\n",
        "            ybinary[k:] = partition\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def mutation(x):\n",
        "    if random.uniform(0,1) < 0.5:\n",
        "        '''Adding a new block'''\n",
        "        if random.uniform(0,1) > 0.5:\n",
        "            #Adding a fully-connected block\n",
        "            layer = {'type' : 'fc',\n",
        "                     'neurons' : random.choice(NEURONS)}\n",
        "\n",
        "            #Choosing a random index to insert the new block\n",
        "            index = list(range(x.n_conv, x.n_conv + x.n_full))\n",
        "            ix = random.choice(index)\n",
        "\n",
        "            x.first_level.insert(ix, layer)\n",
        "            x.n_full += 1\n",
        "\n",
        "        else:\n",
        "            #Adding a convolutional block\n",
        "            layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "            #Choosing a random index to insert the new block\n",
        "            index = list(range(x.n_conv))\n",
        "            ix = random.choice(index)\n",
        "\n",
        "            x.first_level.insert(ix, layer)\n",
        "            x.n_conv += 1\n",
        "\n",
        "            if ix > 1:\n",
        "                new_bits = []\n",
        "                for i in range(ix - 1):\n",
        "                    new_bits.append(random.choice([0,1]))\n",
        "                pos = int(0.5*(ix**2) - 1.5*(ix) + 1)\n",
        "                start = pos + len(new_bits)\n",
        "                for bit in new_bits:\n",
        "                    x.second_level.insert(pos, bit)\n",
        "                    pos += 1\n",
        "\n",
        "                rest = x.n_conv - ix - 1\n",
        "                add = ix\n",
        "                for j in range(rest):\n",
        "                    x.second_level.insert(start+add-1, random.choice([0,1]))\n",
        "                    start += add\n",
        "                    ix += 1\n",
        "\n",
        "            if ix == 0 or ix == 1:\n",
        "                if x.n_conv - 1 == 2:\n",
        "                    x.second_level.append(random.choice([0,1]))\n",
        "                else:\n",
        "                    add = 0\n",
        "                    for i in range(2, x.n_conv):\n",
        "                        pos = int(0.5*(ix**2) - 1.5*(ix) + 1) + add\n",
        "                        x.second_level.insert(pos, random.choice([0,1]))\n",
        "                        add += 1\n",
        "\n",
        "    else:\n",
        "        '''Changing hyperparameters in one block'''\n",
        "        if random.uniform(0,1) > 0.5:\n",
        "            '''Re-starting a fully-connected block'''\n",
        "            index = list(range(x.n_conv, x.n_conv + x.n_full))\n",
        "            ix = random.choice(index)\n",
        "            new_layer = {'type' : 'fc',\n",
        "                         'neurons' : random.choice(NEURONS)}\n",
        "            #Switching fully-connected block\n",
        "            x.first_level[ix] = new_layer\n",
        "\n",
        "        else:\n",
        "            '''Re-starting a convolutional block'''\n",
        "            index = list(range(x.n_conv))\n",
        "            ix = random.choice(index)\n",
        "            new_layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "\n",
        "            #Switching convolutional block\n",
        "            x.first_level[ix] = new_layer\n",
        "\n",
        "        '''Modifying connections in second level'''\n",
        "        if len(x.second_level) > 0:\n",
        "            k = random.choice(list(range(len(x.second_level))))\n",
        "            #Flipping one bit in the second level\n",
        "            if x.second_level[k] == 1:\n",
        "                x.second_level[k] = 0\n",
        "            else:\n",
        "                x.second_level[k] = 1\n",
        "\n",
        "\n",
        "def selection(tournament, style):\n",
        "    '''Stochastic tournament selection'''\n",
        "    if style == 'max':\n",
        "        if random.uniform(0,1) <= 0.8:\n",
        "            p = max(tournament, key = lambda x: x[1])\n",
        "        else:\n",
        "            p = random.choice(tournament)\n",
        "    else:\n",
        "        if random.uniform(0,1) <= 0.8:\n",
        "            p = min(tournament, key = lambda x: x[1])\n",
        "        else:\n",
        "            p = random.choice(tournament)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjVfGIiqZVKh"
      },
      "source": [
        "**EncodingClass.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "-eXaGfTqZX0B"
      },
      "outputs": [],
      "source": [
        "'''Hyperparameters configuration'''\n",
        "#Convolutional layers\n",
        "'''Hyperparameters configuration'''\n",
        "#Convolutional layers\n",
        "FSIZES = [2,3,4,5,6]\n",
        "#FSIZES = [2,3,4,5,6,7,8]\n",
        "NFILTERS = [2,4,8,16,32]\n",
        "\n",
        "#Pooling layers\n",
        "PSIZES = [2,3,4,5]\n",
        "PTYPE = ['max', 'avg']\n",
        "\n",
        "#Fully connected layers\n",
        "NEURONS = [4,8,16,32,64,128]\n",
        "\n",
        "class Encoding:\n",
        "    def __init__(self, minC, maxC, minF, maxF):\n",
        "        self.n_conv = random.randint(minC, maxC)\n",
        "        self.n_full = random.randint(minF, maxF)\n",
        "\n",
        "\n",
        "        '''First level encoding'''\n",
        "        self.first_level = []\n",
        "\n",
        "        #Feature extraction part\n",
        "        for i in range(self.n_conv):\n",
        "            layer = {'type' : 'conv',\n",
        "                     'nfilters' : random.choice(NFILTERS),\n",
        "                     'fsize' : random.choice(FSIZES),\n",
        "                     'pool' : random.choice(['max', 'avg', 'off']),\n",
        "                     'psize' : random.choice(PSIZES)\n",
        "                    }\n",
        "            self.first_level.append(layer)\n",
        "\n",
        "        #Fully connected part\n",
        "        for i in range(self.n_full):\n",
        "            layer = {'type' : 'fc',\n",
        "                     'neurons' : random.choice(NEURONS)}\n",
        "\n",
        "            self.first_level.append(layer)\n",
        "\n",
        "\n",
        "        '''Second level encoding'''\n",
        "        self.second_level = []\n",
        "        prev = -1\n",
        "        for i in range(self.n_conv):\n",
        "            if prev < 1:\n",
        "                prev += 1\n",
        "            if prev >= 1:\n",
        "                for _ in range(prev-1):\n",
        "                    self.second_level.append(random.choice([0,1]))\n",
        "                prev += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFC3Jg0HL7Hk"
      },
      "source": [
        "**Decondig.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "UnLkivWFZc1j"
      },
      "outputs": [],
      "source": [
        "def conv_out_size(W, K):\n",
        "    return W - K + 3\n",
        "\n",
        "def pool_out_size(W, K):\n",
        "    return math.floor((W - K)/2) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "ROxmA9hnZekJ"
      },
      "outputs": [],
      "source": [
        "def decoding(encoding):\n",
        "  n_conv = encoding.n_conv\n",
        "  n_full = encoding.n_full\n",
        "  first_level = encoding.first_level\n",
        "  second_level = encoding.second_level\n",
        "\n",
        "  features = []\n",
        "  classifier = []\n",
        "  in_channels = 1\n",
        "  out_size = 92\n",
        "  prev = -1\n",
        "  pos = 0\n",
        "  o_sizes = []\n",
        "  for i in range(n_conv):\n",
        "    layer = first_level[i]\n",
        "    n_filters = layer['nfilters']\n",
        "    f_size = layer['fsize']\n",
        "    pad = 1\n",
        "    if f_size > out_size:\n",
        "        f_size = out_size - 1\n",
        "    if i == 0 or i == 1:\n",
        "      if layer['pool'] == 'off':\n",
        "        operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                    nn.BatchNorm2d(n_filters),\n",
        "                    nn.ReLU(inplace = True)]\n",
        "        in_channels = n_filters\n",
        "        out_size = conv_out_size(out_size, f_size)\n",
        "        o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'avg':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.AvgPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'max':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.MaxPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "    else:\n",
        "      connections = second_level[pos:pos+prev]\n",
        "      for c in range(len(connections)):\n",
        "        if connections[c] == 1:\n",
        "          in_channels += o_sizes[c][1]\n",
        "\n",
        "      if layer['pool'] == 'off':\n",
        "        operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                    nn.BatchNorm2d(n_filters),\n",
        "                    nn.ReLU(inplace = True)]\n",
        "        in_channels = n_filters\n",
        "        out_size = conv_out_size(out_size, f_size)\n",
        "        o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'avg':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.AvgPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      if layer['pool'] == 'max':\n",
        "          p_size = layer['psize']\n",
        "          if p_size > out_size:\n",
        "              p_size = out_size - 1\n",
        "          operation = [nn.Conv2d(in_channels = in_channels, out_channels = n_filters, kernel_size = f_size, padding = pad),\n",
        "                      nn.BatchNorm2d(n_filters),\n",
        "                      nn.ReLU(inplace = True),\n",
        "                      nn.MaxPool2d(kernel_size = p_size, stride = 2)]\n",
        "          in_channels = n_filters\n",
        "          out_size = conv_out_size(out_size, f_size)\n",
        "          out_size = pool_out_size(out_size, p_size)\n",
        "          o_sizes.append([out_size, in_channels])\n",
        "\n",
        "      pos += prev\n",
        "    prev += 1\n",
        "\n",
        "    features.append(operation)\n",
        "  in_size = out_size*out_size*in_channels\n",
        "  for i in range(n_conv,(n_conv + n_full)):\n",
        "    layer = first_level[i]\n",
        "    n_neurons = layer['neurons']\n",
        "    classifier += [nn.Linear(in_size, n_neurons)]\n",
        "    classifier += [nn.ReLU(inplace = True)]\n",
        "    in_size = n_neurons\n",
        "\n",
        "  ##Last layer generates the last neurons for softmax (change this for binary classification)\n",
        "  classifier += [nn.Linear(n_neurons, 6)]\n",
        "\n",
        "  return features, classifier, o_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "Hrs1qc3JZhcF"
      },
      "outputs": [],
      "source": [
        "'''Networks class'''\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, encoding, features, classifier, sizes, init_weights = True):\n",
        "    super(CNN, self).__init__()\n",
        "    extraction = []\n",
        "    for layer in features:\n",
        "      extraction += layer\n",
        "    self.extraction = nn.Sequential(*extraction)\n",
        "    self.classifier = nn.Sequential(*classifier)\n",
        "    self.features = features\n",
        "    self.second_level = encoding.second_level\n",
        "    self.sizes = sizes\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''Feature extraction'''\n",
        "    prev = -1\n",
        "    pos = 0\n",
        "    outputs = {}\n",
        "    features = self.features\n",
        "    #print(x.shape)\n",
        "    for i in range(len(features)):\n",
        "      #print('Layer: ', i)\n",
        "      if i == 0 or i == 1:\n",
        "        x = nn.Sequential(*features[i])(x)\n",
        "        outputs[i] = x\n",
        "        #print(x.shape)\n",
        "\n",
        "      else:\n",
        "        connections = self.second_level[pos:pos+prev]\n",
        "        for c in range(len(connections)):\n",
        "          if connections[c] == 1:\n",
        "            skip_size = self.sizes[c][0] #Size comming from previous layer\n",
        "            req_size = x.shape[2] #Current feature map size\n",
        "            #print('X: ',x.shape)\n",
        "            if skip_size > req_size:\n",
        "              psize = skip_size - req_size + 1\n",
        "              pool = nn.MaxPool2d(kernel_size = psize, stride = 1) #Applying pooling to adjust sizes\n",
        "              x2 = pool(outputs[c])\n",
        "            if skip_size == req_size:\n",
        "              x2 = outputs[c]\n",
        "            if req_size == skip_size + 1:\n",
        "              pool = nn.MaxPool2d(kernel_size = 2, stride = 1, padding = (1,1))\n",
        "              x2 = pool(outputs[c])\n",
        "            if req_size == skip_size + 2:\n",
        "              pad = int((req_size - skip_size)/2)\n",
        "              padding = nn.ZeroPad2d(pad)\n",
        "              x2 = padding(outputs[c])\n",
        "            #print('X2: ',x2.shape)\n",
        "            x = torch.cat((x, x2), axis = 1)\n",
        "\n",
        "        x = nn.Sequential(*features[i])(x)\n",
        "        #print('Out size: ', x.shape)\n",
        "        outputs[i] = x\n",
        "        pos += prev\n",
        "\n",
        "      prev += 1\n",
        "\n",
        "    #print('Classification size: ', x.shape)\n",
        "    x = torch.flatten(x,1)\n",
        "    '''Classification'''\n",
        "    '''for l in self.classifier:\n",
        "      x = l(x)'''\n",
        "    x = self.classifier(x)\n",
        "    # return x\n",
        "    #print(x.shape)\n",
        "    return nn.functional.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTbwT-I7ZG6H"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QBRp3dIZJcg",
        "outputId": "6f857d20-6a3e-4158-aebc-69137052b102"
      },
      "outputs": [],
      "source": [
        "# #Mounting Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4e6T3hPGi01"
      },
      "source": [
        "**DataReader.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "7byf3HzsZOjR"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.labels = []  # Lista de etiquetas de clase\n",
        "        self.datos = []\n",
        "        file_csv = os.path.join(\n",
        "            root_dir, \"dataset_to_deepga.csv\")\n",
        "        data = np.loadtxt(file_csv, delimiter=',', skiprows=0)\n",
        "        # Removemos la última columnas\n",
        "        label = data[:, -1]  # Obtenemos la clase\n",
        "        self.labels = label.astype(int)\n",
        "        self.datos = data[:, :-1]  # Obtenemos los datos\n",
        "        # Sección para agregar 26 columnas con la finalidad de realizar el reshape\n",
        "        # tam = data.shape[0];\n",
        "        # complemento = np.zeros((tam,26))\n",
        "        # self.datos = np.concatenate([complemento, data], axis=1)\n",
        "        # self.datos = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = self.datos[idx]\n",
        "        # vect2 = np.zeros(26, dtype=float)\n",
        "        # image = np.concatenate([vect2, image], axis=None)\n",
        "        # Redimensionar la imagen a 92\n",
        "        image = np.array(image)\n",
        "        # print(image.shape)\n",
        "        image = image.reshape(92, 92)\n",
        "        [H, W] = image.shape\n",
        "        image = image.reshape((H, W, -1))\n",
        "        # print(image)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        sample = {\"image\": image, \"label\": label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample[\"image\"], sample[\"label\"]\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {\"image\": torch.from_numpy(image), \"label\": label}\n",
        "\n",
        "\n",
        "def loading_data():\n",
        "    root_dir = '../../../../data_img_test'\n",
        "    custom_dataset = CustomDataset(\n",
        "        root_dir=root_dir, transform=transforms.Compose([ToTensor()]))\n",
        "\n",
        "    train_size = int(0.7 * len(custom_dataset))\n",
        "    test_size = len(custom_dataset) - train_size\n",
        "\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        custom_dataset, [train_size, test_size])\n",
        "    # print('Custom datset size : ', len(custom_dataset))\n",
        "    # print('Data size training: ', len(train_dataset))\n",
        "    # print('Data size test: ', len(test_dataset))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=30, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=30, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVmaNMkuLBNN",
        "outputId": "dd09f578-ac25-4dfe-b398-7da8df63ab5a"
      },
      "outputs": [],
      "source": [
        "train_dl, test_dl = loading_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "mZ1DCHUPMPry"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 1, 92, 92])\n",
            "tensor([0, 5, 4, 5, 0, 3, 1, 3, 5, 0, 3, 3, 0, 4, 5, 4, 5, 5, 3, 5, 5, 4, 4, 5,\n",
            "        5, 3, 3, 0, 4, 4])\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Dimensiones del tensor test\"\"\"\n",
        "for i_batch,sample_batched in enumerate(test_dl):\n",
        "  print(sample_batched['image'].shape)\n",
        "  print(sample_batched['label'])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "ieYKLeNBMWLx",
        "outputId": "c1805557-884c-42ab-f67d-029cf96ec6bc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_batched['image'][0]\n",
        "imagen = sample_batched['image'][0]\n",
        "imagen = np.squeeze(imagen)\n",
        "# Muestra la imagen en escala de grises\n",
        "plt.imshow(imagen,cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLJ79lVaZ3dB"
      },
      "source": [
        "**DistributedTraining.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "llQFTX8HZ5Ht"
      },
      "outputs": [],
      "source": [
        "def loss_batch(loss_func, xb, yb, yb_h, opt=None):\n",
        "    # Obtain the loss\n",
        "    size_yh = yb_h.size()\n",
        "    size_y = yb.size()\n",
        "    # print(size_yh)\n",
        "    # print(size_y)\n",
        "    loss = loss_func(yb_h, yb)\n",
        "    # Obtain peformance metric\n",
        "    metric_b = metrics_batch(yb, yb_h)\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), metric_b\n",
        "    # return metric_b\n",
        "\n",
        "# Helper function to compute the accuracy per mini_batch\n",
        "\n",
        "\n",
        "def metrics_batch(target, output):\n",
        "    # Obtain output class\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    # Compare output class with target class\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    return corrects\n",
        "\n",
        "# Helper function to compute the loss and metric values for a dataset\n",
        "\n",
        "\n",
        "def loss_epoch(device, model, loss_func, dataset_dl, opt=None):\n",
        "    loss = 0.0\n",
        "    metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "    for i, data in enumerate(dataset_dl, 0):\n",
        "        # print('batch: ', i)\n",
        "        xb, yb = data['image'], data['label']\n",
        "        xb = xb.type(torch.double).to(device, dtype=torch.float32)\n",
        "        yb = yb.to(device, dtype=torch.long)\n",
        "\n",
        "        # Obtain model output\n",
        "        yb_h = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, xb, yb, yb_h, opt)\n",
        "        loss += loss_b\n",
        "        if metric_b is not None:\n",
        "            metric += metric_b\n",
        "\n",
        "    loss /= len_data\n",
        "    metric /= len_data\n",
        "\n",
        "    return loss, metric\n",
        "    # return metric\n",
        "\n",
        "# Define the training function\n",
        "\n",
        "\n",
        "def train_val(device, epochs, model, opt, loss_func, train_dl, test_dl):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # print(epoch)\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(\n",
        "            device, model, loss_func, train_dl, opt)\n",
        "        # train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(\n",
        "                device, model, loss_func, test_dl)\n",
        "            # val_metric = loss_epoch(model, loss_func, test_dl)\n",
        "        accuracy = val_metric\n",
        "\n",
        "        # print(\"Epoch: %d, train loss: %.6f, val loss: %.6f, test accuracy: %.2f\" %(epoch, train_loss, val_loss, accuracy))\n",
        "\n",
        "    return accuracy, model\n",
        "\n",
        "\n",
        "def training(num, device, model, n_epochs, loss_func, train_dl, test_dl, lr, w, max_params):\n",
        "    # Number of parameters\n",
        "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Obtaining training accuracy\n",
        "    accuracy, _ = train_val(device, n_epochs, model, opt,\n",
        "                            loss_func, train_dl, test_dl)\n",
        "\n",
        "    # Fitness function based on accuracy and No. of parameters\n",
        "    # f = abs(accuracy - w*(1 - abs((max_params - params)/max_params)))\n",
        "    f = (1 - w)*accuracy + w*((max_params - params)/max_params)\n",
        "    '''if params < max_params:\n",
        "        f = (1 - w)*accuracy + abs(w*((max_params - params)/max_params))'''\n",
        "    '''else:\n",
        "        #f = (1 - w)*accuracy - abs(w*((max_params - params)/max_params))\n",
        "        f = accuracy - abs((max_params - params)/max_params)'''\n",
        "\n",
        "    # Append results to multiprocessing list\n",
        "    # acc_list.append([num, f, accuracy, params])\n",
        "    return num, f, accuracy, params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieZzagSsYOaj"
      },
      "source": [
        "**Loading GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEdRSBJoYQbx",
        "outputId": "657bceed-5124-4d4a-f88e-17e6670b09cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.cudaStatus.ERROR_NOT_READY)\n",
        "if torch.cuda.is_available():\n",
        "  # device1 = torch.device(\"cuda:0\")\n",
        "  device1 = torch.device(\"cpu\")\n",
        "  print(device1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dXCfouwaYbN"
      },
      "source": [
        "**DeepGA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "HCsj6taeabkX"
      },
      "outputs": [],
      "source": [
        "#Maximun and minimum numbers of layers to initialize networks\n",
        "min_conv = 2\n",
        "max_conv = 6\n",
        "min_full = 1\n",
        "max_full = 6\n",
        "\n",
        "'''Genetic Algorithm Parameters'''\n",
        "cr = 0.7 #Crossover rate\n",
        "mr = 0.5 #Mutation rate\n",
        "N = 20 #Population size\n",
        "T = 50 #Number of generations\n",
        "t_size = 6 #tournament size\n",
        "w = 0.3 #penalization weight\n",
        "max_params = 3e6\n",
        "num_epochs = 5 # TODO: retrunt to 50\n",
        "lr = 1e-3\n",
        "# loss_func = nn.NLLLoss(reduction = \"sum\")\n",
        "# loss_func = nn.NLLLoss()\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPU_DA7sbHbe",
        "outputId": "9ef287c9-cf7c-4c56-8d42-b65eb492fc58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialize population\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation:  0\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from multiprocessing import Process, Manager\n",
        "from torchsummary import summary\n",
        "\n",
        "'''Initialize population'''\n",
        "print('Initialize population')\n",
        "\n",
        "# train_dl, test_dl = loading_data()\n",
        "\n",
        "start = timeit.default_timer()\n",
        "pop = []\n",
        "bestAcc = []\n",
        "bestF = []\n",
        "bestParams = []\n",
        "# manager = Manager()\n",
        "while len(pop) < N:\n",
        "    # acc_list = manager.list()\n",
        "\n",
        "    # Creating genomes (genetic encoding)\n",
        "    e1 = Encoding(min_conv, max_conv, min_full, max_full)\n",
        "    # e2 = Encoding(min_conv,max_conv,min_full,max_full)\n",
        "\n",
        "    # Decoding the networks\n",
        "    network1 = decoding(e1)\n",
        "    # network2 = decoding(e2)\n",
        "    # print(network1)\n",
        "\n",
        "    # Creating the CNNs\n",
        "    # print(network1[2])\n",
        "    cnn1 = CNN(e1, network1[0], network1[1], network1[2])\n",
        "    # cnn2 = CNN(e2, network2[0], network2[1], network2[2])\n",
        "    # Evaluate individuals\n",
        "    num1, f1, accuracy1, params1 = training('1', device1, cnn1, num_epochs, loss_func,\n",
        "                                            train_dl, test_dl, lr, w, max_params)\n",
        "\n",
        "    # training2 = Process(target = training, args = ('2', device2, cnn2, num_epochs, loss_func,\n",
        "    #                                              train_dl, test_dl, lr, w, max_params, acc_list))\n",
        "\n",
        "    # training1.start()\n",
        "    # training2.start()\n",
        "    # training1.join()\n",
        "    # training2.join()\n",
        "\n",
        "    # if acc_list[0][0] == '1':\n",
        "    pop.append([e1, f1, accuracy1, params1])\n",
        "    # pop.append([e2, acc_list[1][1], acc_list[1][2], acc_list[1][3]])\n",
        "    # else:\n",
        "    # pop.append([e2, acc_list[0][1], acc_list[0][2], acc_list[0][3]])\n",
        "    # pop.append([e1, acc_list[1][1], acc_list[1][2], acc_list[1][3]])\n",
        "\n",
        "'''Genetic Algorithm'''\n",
        "for t in range(T):\n",
        "    print('Generation: ', t)\n",
        "\n",
        "    # Parents Selection\n",
        "    parents = []\n",
        "    while len(parents) < int(N/2):\n",
        "        # Tournament Selection\n",
        "        tournament = random.sample(pop, t_size)\n",
        "        p1 = selection(tournament, 'max')\n",
        "        tournament = random.sample(pop, t_size)\n",
        "        p2 = selection(tournament, 'max')\n",
        "        while p1 == p2:\n",
        "            tournament = random.sample(pop, t_size)\n",
        "            p2 = selection(tournament, 'max')\n",
        "\n",
        "        parents.append(p1)\n",
        "        parents.append(p2)\n",
        "\n",
        "    # Reproduction\n",
        "    offspring = []\n",
        "    while len(offspring) < int(N/2):\n",
        "        par = random.sample(parents, 2)\n",
        "        # Crossover + Mutation\n",
        "        if cr >= random.uniform(0, 1):  # Crossover\n",
        "            p1 = par[0][0]\n",
        "            p2 = par[1][0]\n",
        "            c1, c2 = crossover(p1, p2)\n",
        "\n",
        "            # Mutation\n",
        "            if mr >= random.uniform(0, 1):\n",
        "                mutation(c1)\n",
        "\n",
        "            if mr >= random.uniform(0, 1):\n",
        "                mutation(c2)\n",
        "\n",
        "            # Evaluate offspring\n",
        "            # acc_list = manager.list()\n",
        "\n",
        "            # Decoding the network\n",
        "            network1 = decoding(c1)\n",
        "            network2 = decoding(c2)\n",
        "\n",
        "            # Creating the CNN\n",
        "            cnn1 = CNN(c1, network1[0], network1[1], network1[2])\n",
        "            cnn2 = CNN(c2, network2[0], network2[1], network2[2])\n",
        "\n",
        "            # Evaluate individuals\n",
        "            num_cnn1, f_cnn1, accuracy_cnn1, params_cnn1 = training('1', device1, cnn1, num_epochs, loss_func,\n",
        "                                                                    train_dl, test_dl, lr, w, max_params)\n",
        "            offspring.append([c1, f_cnn1, accuracy_cnn1, params_cnn1])\n",
        "\n",
        "            num_cnn2, f_cnn2, accuracy_cnn2, params_cnn2 = training('2', device1, cnn2, num_epochs, loss_func,\n",
        "                                                                    train_dl, test_dl, lr, w, max_params)\n",
        "            offspring.append([c2, f_cnn2, accuracy_cnn2, params_cnn2])\n",
        "\n",
        "    # Replacement with elitism\n",
        "    pop = pop + offspring\n",
        "    pop.sort(reverse=True, key=lambda x: x[1])\n",
        "    pop = pop[:N]\n",
        "\n",
        "    leader = max(pop, key=lambda x: x[1])\n",
        "    bestAcc.append(leader[2])\n",
        "    bestF.append(leader[1])\n",
        "    bestParams.append(leader[3])\n",
        "\n",
        "    print('Best fitness: ', leader[1])\n",
        "    print('Best accuracy: ', leader[2])\n",
        "    print('Best No. of Params: ', leader[3])\n",
        "    print('No. of Conv. Layers: ', leader[0].n_conv)\n",
        "    print('No. of FC Layers: ', leader[0].n_full)\n",
        "    print('--------------------------------------------')\n",
        "\n",
        "results = pd.DataFrame(list(zip(bestAcc, bestF, bestParams)), columns=[\n",
        "                       'Accuracy', 'Fitness', 'No. Params'])\n",
        "final_networks = []\n",
        "final_connections = []\n",
        "objects = []\n",
        "for member in pop:\n",
        "    p = member[0]\n",
        "    objects.append(p)\n",
        "    n_conv = p.n_conv\n",
        "    n_full = p.n_full\n",
        "    description = 'The network has ' + \\\n",
        "        str(n_conv) + ' convolutional layers ' + 'with: '\n",
        "    for i in range(n_conv):\n",
        "        nfilters = str(p.first_level[i]['nfilters'])\n",
        "        fsize = str(p.first_level[i]['fsize'])\n",
        "        pool = str(p.first_level[i]['pool'])\n",
        "        psize = str(p.first_level[i]['psize'])\n",
        "        layer = '(' + nfilters + ', ' + fsize + \\\n",
        "            ', ' + pool + ', ' + psize + ') '\n",
        "        description += layer\n",
        "    description += 'and '\n",
        "    description += str(n_full)\n",
        "    description += ' '\n",
        "    description += 'fully-connected layers with: '\n",
        "    for i in range(n_conv, n_conv+n_full):\n",
        "        neurons = str(p.first_level[i]['neurons'])\n",
        "        layer = '(' + neurons + ')'\n",
        "        description += layer\n",
        "    description += ' neurons'\n",
        "    final_networks.append(description)\n",
        "\n",
        "    connections = ''\n",
        "    for bit in p.second_level:\n",
        "        if bit == 1:\n",
        "            connections += 'one - '\n",
        "        if bit == 0:\n",
        "            connections += 'zero - '\n",
        "    final_connections.append(connections)\n",
        "\n",
        "\n",
        "final_population = pd.DataFrame(list(zip(final_networks, final_connections)), columns=[\n",
        "                                'Network Architecture', 'Connections'])\n",
        "\n",
        "'''Saving Results as CSV'''\n",
        "final_population.to_csv('final_population.csv', index=False)\n",
        "results.to_csv('results.csv', index=False)\n",
        "stop = timeit.default_timer()\n",
        "execution_time = (stop-start)/3600\n",
        "print(\"Execution time: \", execution_time)\n",
        "\n",
        "# Saving objects\n",
        "\n",
        "with open('cnns.pkl', 'wb') as output:\n",
        "    pickle.dump(objects, output, pickle.HIGHEST_PROTOCOL)\n",
        "    output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-w0gY20isaY"
      },
      "outputs": [],
      "source": [
        "# !cp final_population.csv /content/gdrive/MyDrive/Ricardo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_KxIgYQkFs3"
      },
      "outputs": [],
      "source": [
        "# !cp result.csv /content/gdrive/MyDrive/Ricardo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCk9-7bUkLhH"
      },
      "outputs": [],
      "source": [
        "# !cp cnns.pkl /content/gdrive/MyDrive/Ricardo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "hqh1fTflGHK4",
        "outputId": "7e428c5e-546e-46a1-840d-c9130c9e84a2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJXgj7AOV2OT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "model = pickle.load(open(\"cnns.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep7abBCVWhe-"
      },
      "outputs": [],
      "source": [
        "\n",
        "final_networks = []\n",
        "final_connections = []\n",
        "objects = []\n",
        "for member in output:\n",
        "    p = member\n",
        "    objects.append(p)\n",
        "    n_conv = p.n_conv\n",
        "    n_full = p.n_full\n",
        "    description = 'The network has ' + str(n_conv) + ' convolutional layers ' + 'with: '\n",
        "    for i in range(n_conv):\n",
        "        nfilters = str(p.first_level[i]['nfilters'])\n",
        "        fsize = str(p.first_level[i]['fsize'])\n",
        "        pool = str(p.first_level[i]['pool'])\n",
        "        psize = str(p.first_level[i]['psize'])\n",
        "        layer = '(' + nfilters + ', ' + fsize + ', ' + pool + ', ' + psize + ') '\n",
        "        description += layer\n",
        "    description += 'and '\n",
        "    description += str(n_full)\n",
        "    description += ' '\n",
        "    description += 'fully-connected layers with: '\n",
        "    for i in range(n_conv, n_conv+n_full):\n",
        "        neurons = str(p.first_level[i]['neurons'])\n",
        "        layer = '(' + neurons + ')'\n",
        "        description += layer\n",
        "    description += ' neurons'\n",
        "    final_networks.append(description)\n",
        "\n",
        "    connections = ''\n",
        "    for bit in p.second_level:\n",
        "        if bit == 1:\n",
        "            connections += 'one - '\n",
        "        if bit == 0:\n",
        "            connections += 'zero - '\n",
        "    final_connections.append(connections)\n",
        "\n",
        "\n",
        "#final_population = pd.DataFrame(list(zip(final_networks, final_connections)), columns = ['Network Architecture', 'Connections'])\n",
        "\n",
        "'''Saving Results as CSV'''\n",
        "#final_population.to_csv('final_population.csv', index = False)\n",
        "#results.to_csv('results.csv', index = False)\n",
        "#stop = timeit.default_timer()\n",
        "#execution_time = (stop-start)/3600\n",
        "#print(\"Execution time: \", execution_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s6zz8ujYLKw"
      },
      "outputs": [],
      "source": [
        "final_networks"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
